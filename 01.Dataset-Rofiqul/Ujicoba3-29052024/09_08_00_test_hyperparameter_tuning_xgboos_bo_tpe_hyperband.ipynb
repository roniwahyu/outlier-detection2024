{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# Assume you have your data loaded as X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bayesian Optimization\n",
    "def xgb_bayesian_opt(max_depth, learning_rate, n_estimators, subsample, colsample_bytree):\n",
    "    model = xgb.XGBRegressor(max_depth=int(max_depth),\n",
    "                            learning_rate=learning_rate,\n",
    "                            n_estimators=int(n_estimators),\n",
    "                            subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = -mean_squared_error(y_test, model.predict(X_test))\n",
    "    return score\n",
    "\n",
    "xgb_bo = BayesianOptimization(xgb_bayesian_opt, {\n",
    "    'max_depth': (4, 10),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'n_estimators': (100, 500),\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1)\n",
    "})\n",
    "xgb_bo.maximize(init_points=5, n_iter=25)\n",
    "best_params_bo = xgb_bo.max['params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tree-structured Parzen Estimator (TPE)\n",
    "def xgb_tpe(params):\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = -mean_squared_error(y_test, model.predict(X_test))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 4, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 500, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_params_tpe = fmin(xgb_tpe, space, algo=tpe.suggest, max_evals=25, trials=trials)\n",
    "best_params_tpe = {\n",
    "    'max_depth': int(best_params_tpe['max_depth']),\n",
    "    'learning_rate': best_params_tpe['learning_rate'],\n",
    "    'n_estimators': int(best_params_tpe['n_estimators']),\n",
    "    'subsample': best_params_tpe['subsample'],\n",
    "    'colsample_bytree': best_params_tpe['colsample_bytree']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperband\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def xgb_hyperband(params):\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return {'loss': -np.mean(scores), 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 4, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 500, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "best_params_hyperband = fmin(xgb_hyperband, space, algo=partial(tpe.suggest, n_startup_jobs=10), max_evals=25)\n",
    "best_params_hyperband = {\n",
    "    'max_depth': int(best_params_hyperband['max_depth']),\n",
    "    'learning_rate': best_params_hyperband['learning_rate'],\n",
    "    'n_estimators': int(best_params_hyperband['n_estimators']),\n",
    "    'subsample': best_params_hyperband['subsample'],\n",
    "    'colsample_bytree': best_params_hyperband['colsample_bytree']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train final models with the best hyperparameters found\n",
    "model_bo = xgb.XGBRegressor(**best_params_bo, random_state=42)\n",
    "model_tpe = xgb.XGBRegressor(**best_params_tpe, random_state=42)\n",
    "model_hyperband = xgb.XGBRegressor(**best_params_hyperband, random_state=42)\n",
    "\n",
    "model_bo.fit(X_train, y_train)\n",
    "model_tpe.fit(X_train, y_train)\n",
    "model_hyperband.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
