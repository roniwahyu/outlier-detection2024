{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SG0c2_O1J8UJ","outputId":"574b177b-ade9-4586-c66b-e0ff512bd34c","executionInfo":{"status":"ok","timestamp":1729491931558,"user_tz":-420,"elapsed":25489,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkIwO501KIhe","outputId":"d5b117c7-9bfa-4008-baa5-175746ed5ff1","executionInfo":{"status":"ok","timestamp":1729491931558,"user_tz":-420,"elapsed":3,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Disertasi-Ahmad-Rofiqul/002.Experiment_SWI_16052024\n"]}],"source":["# Path to google drive folder\n","# %cd /content/drive/MyDrive/Colab Notebooks/Disertasi-Ahmad-Rofiqul/002. Laporan-eksperimen\n","\n","%cd /content/drive/MyDrive/Colab Notebooks/Disertasi-Ahmad-Rofiqul/002.Experiment_SWI_16052024/"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"E3maRHbiKSMZ","executionInfo":{"status":"ok","timestamp":1729491947262,"user_tz":-420,"elapsed":15706,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy import stats\n","from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n","from sklearn.ensemble import IsolationForest, RandomForestClassifier\n","from sklearn.cluster import DBSCAN\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import classification_report\n","from xgboost import XGBRegressor, DMatrix, cv\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","from sklearn.svm import OneClassSVM\n","from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","import xgboost as xgb"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSf0yMJ6-dxS","executionInfo":{"status":"ok","timestamp":1729491947262,"user_tz":-420,"elapsed":5,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"4b793a1d-3288-4e5e-a6a3-679f0523231d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["'010_01_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_OUTLIERS_DETECTION_Uji Performance.ipynb'\n","'010_02_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_OUTLIERS_DETECTION_Uji Performance_consensus_scoring.ipynb'\n","'010_04_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_OUTLIERS_DETECTION_weighted_voting (iA).ipynb'\n","'011_01_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_OUTLIERS_DETECTION_Uji Performance 13092024.ipynb'\n"," 01.Dataset-Rofiqul\n"," 09_03_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_NOIQR_OUTLIERS_DETECTION_UPDATE24052024.ipynb\n"," 09_03_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_OUTLIERS_DETECTION_update23052024.ipynb\n"," 09_03_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_+_XGBoost.ipynb\n","'09_03_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_+_XGBoost_SWI(1).ipynb'\n"," 09_03_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_+_XGBoost_SWI_Update21052024.ipynb\n"," 09_04_1_Agricultural_N2O_IDO_Training_Testing_Plain_SWI_22052024.ipynb\n"," 09_04_1_Agricultural_N2O_IDO_Training_Testing_Plain_SWI_23052024.ipynb\n"," 09_04_2_1_Agricultural_N2O_IDO_Training_Testing_Plain_Inlier_24052024.ipynb\n"," 09_04_2_2_Agricultural_N2O_IDO_Training_Testing_Plain_Skenario_DataUji_24052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_InliersOnly_Uji_Dataset_CrossVal_SWI_24052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_Skema_Uji_Dataset_CrossVal_DMatrix_SWI_22052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_Skema_Uji_Dataset_CrossVal_SWI_22052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_Skema_Uji_Dataset_NoCrossVal_SWI_22052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_Skema_Uji_Dataset_SWI_22052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_Skema_Uji_HyperparameterTuning_SWI_22052024.ipynb\n"," 09_04_2_Agricultural_N2O_IDO_Skema_Uji_HyperparameterTuning_SWI_24052024.ipynb\n"," 09_04_3_Agricultural_N2O_IDO_XGBoost_CrossVal_Comparison.ipynb\n"," 09_04_Agricultural_N2O_IDO_Training_Testing_DataTesting_SWI_22052024\n"," 09_04_Agricultural_N2O_IDO_Training_Testing_Plain_SWI_22052024.ipynb\n"," best_xgboost_evaluation_results.csv\n"," cleaned_agriculture_dataset.csv\n","'Copy of 09.02.Agriculture-N2O-IF-DBSCAN-OneClassSVM + XGBoost-SWI.ipynb'\n","'Copy of 09_03_Agriculture_N2O_IF_DBSCAN_OneClassSVM_Ensemble_+_XGBoost-SWI.ipynb'\n"," deteksi_outlier_isolation_forest.csv\n"," deteksi_outlier_isolation_forest_dbscan.csv\n"," deteksi_outlier_isolation_forest_dbscan_svm_stacking.csv\n"," deteksi_outlier_oneclass_svm.csv\n"," ground_truth_majority_voting.csv\n"," n2o_predictions.csv\n"," perbandingan_hasil_deteksi_outlier.csv\n"," xgboost_gridsearchcv_results.png\n"," xgboost_randomizedsearchcv_tuning_results.csv\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cB3eaRnqKU1A","outputId":"a3223831-1ec0-4a5b-c40b-550679403f01","executionInfo":{"status":"ok","timestamp":1729491948135,"user_tz":-420,"elapsed":875,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2246 entries, 0 to 2245\n","Data columns (total 21 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Date         2246 non-null   object \n"," 1   Year         2246 non-null   int64  \n"," 2   Experiment   2246 non-null   object \n"," 3   DataUse      2246 non-null   object \n"," 4   Replication  2246 non-null   object \n"," 5   Month        2246 non-null   object \n"," 6   Vegetation   2246 non-null   object \n"," 7   VegType      2246 non-null   object \n"," 8   N2O          2246 non-null   float64\n"," 9   N_rate       2246 non-null   int64  \n"," 10  PP2          2246 non-null   float64\n"," 11  PP7          2246 non-null   float64\n"," 12  AirT         2246 non-null   float64\n"," 13  DAF_TD       2246 non-null   int64  \n"," 14  DAF_SD       2246 non-null   int64  \n"," 15  WFPS25cm     2194 non-null   float64\n"," 16  NH4          2170 non-null   float64\n"," 17  NO3          2216 non-null   float64\n"," 18  Clay         2246 non-null   float64\n"," 19  Sand         2246 non-null   float64\n"," 20  SOM          2246 non-null   float64\n","dtypes: float64(10), int64(4), object(7)\n","memory usage: 368.6+ KB\n"]},{"output_type":"execute_result","data":{"text/plain":["(      Date  Year Experiment   DataUse Replication     Month Vegetation  \\\n"," 0   2/9/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 1  2/10/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 2  2/18/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 3  2/19/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 4  3/16/12  2012   BCSE_KBS  Building          R1     March       Corn   \n"," \n","   VegType       N2O  N_rate  ...   PP7  AirT  DAF_TD  DAF_SD  WFPS25cm  \\\n"," 0  Annual  3.896742     170  ...  0.00  -2.0     276     241  0.666508   \n"," 1  Annual  2.190218     170  ...  0.00  -2.4     277     242  0.640608   \n"," 2  Annual  3.542594     170  ...  8.64   0.3     285     250  0.728085   \n"," 3  Annual  3.342870     170  ...  8.13  -3.8     286     251  0.686872   \n"," 4  Annual  2.947778     170  ...  8.39  17.6     312     277  0.716221   \n"," \n","          NH4        NO3  Clay   Sand       SOM  \n"," 0  11.046340  22.940812  62.5  637.5  1.174072  \n"," 1  11.008087  22.959578  62.5  637.5  1.174072  \n"," 2  10.831669  23.221928  62.5  637.5  1.174072  \n"," 3  10.849792  23.271978  62.5  637.5  1.174072  \n"," 4  10.204748  24.206855  62.5  637.5  1.174072  \n"," \n"," [5 rows x 21 columns],\n"," None,\n","               Year          N2O       N_rate          PP2          PP7  \\\n"," count  2246.000000  2246.000000  2246.000000  2246.000000  2246.000000   \n"," mean   2011.925200     7.468610   142.994212     5.219839    19.245273   \n"," std       3.617418    28.488257    56.130412    10.064123    23.723416   \n"," min    2002.000000    -7.415297     0.000000     0.000000     0.000000   \n"," 25%    2011.000000     0.504316   135.000000     0.000000     3.560000   \n"," 50%    2013.000000     1.972058   170.000000     0.510000    11.930000   \n"," 75%    2014.000000     5.187618   170.000000     6.000000    27.000000   \n"," max    2017.000000   593.072000   213.000000    95.250000   260.090000   \n"," \n","               AirT       DAF_TD       DAF_SD     WFPS25cm          NH4  \\\n"," count  2246.000000  2246.000000  2246.000000  2194.000000  2170.000000   \n"," mean     12.408699   195.321015   198.898041     0.531047    11.451364   \n"," std       9.490152   144.915448   142.907436     0.171868    13.214895   \n"," min     -20.700000     1.000000     0.000000     0.024388     1.383393   \n"," 25%       5.940000    73.250000    75.000000     0.390203     5.290323   \n"," 50%      14.490000   160.000000   172.000000     0.553853     9.081282   \n"," 75%      20.070000   308.750000   320.000000     0.680321    12.140325   \n"," max      30.700000   718.000000   678.000000     0.912113   228.525000   \n"," \n","                NO3         Clay         Sand          SOM  \n"," count  2216.000000  2246.000000  2246.000000  2246.000000  \n"," mean     24.997063   134.425163   462.686739     1.901503  \n"," std      24.941785    79.564891   219.451957     1.132896  \n"," min       0.370070    62.500000    55.000000     1.174072  \n"," 25%      10.184722    62.500000   418.833333     1.174072  \n"," 50%      19.795863   128.333333   491.666667     1.186800  \n"," 75%      27.085459   183.250000   637.500000     1.823200  \n"," max     238.920000   280.000000   637.500000     4.500000  )"]},"metadata":{},"execution_count":5}],"source":["# Load the dataset\n","file_path = '01.Dataset-Rofiqul/agriculture_dataset.csv'\n","data = pd.read_csv(file_path)\n","\n","# Display the first few rows of the dataset for review\n","data.head(),data.info(),data.describe()"]},{"cell_type":"markdown","metadata":{"id":"cvC5kqWgyvO3"},"source":["## Detect Nilai NaN"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":742},"id":"gDng0fbFyr3m","outputId":"f8cb2ace-1833-4725-a517-5476efe72bb3","executionInfo":{"status":"ok","timestamp":1729491948135,"user_tz":-420,"elapsed":8,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date            0\n","Year            0\n","Experiment      0\n","DataUse         0\n","Replication     0\n","Month           0\n","Vegetation      0\n","VegType         0\n","N2O             0\n","N_rate          0\n","PP2             0\n","PP7             0\n","AirT            0\n","DAF_TD          0\n","DAF_SD          0\n","WFPS25cm       52\n","NH4            76\n","NO3            30\n","Clay            0\n","Sand            0\n","SOM             0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Date</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Year</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Experiment</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DataUse</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Replication</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Month</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Vegetation</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>VegType</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>N2O</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>N_rate</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>PP2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>PP7</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AirT</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DAF_TD</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DAF_SD</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>WFPS25cm</th>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>NH4</th>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>NO3</th>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>Clay</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Sand</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>SOM</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":6}],"source":["\n","missing_values_count = data.isna().sum()\n","missing_values_count"]},{"cell_type":"markdown","metadata":{"id":"yzcM1q5Ay_KD"},"source":["## Impute NaN or missing value with Mean"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":742},"id":"cT6ViegGy-Xx","outputId":"18ce0374-a687-4812-f0c9-1ab80c19f0ee","executionInfo":{"status":"ok","timestamp":1729491948135,"user_tz":-420,"elapsed":5,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date           0\n","Year           0\n","Experiment     0\n","DataUse        0\n","Replication    0\n","Month          0\n","Vegetation     0\n","VegType        0\n","N2O            0\n","N_rate         0\n","PP2            0\n","PP7            0\n","AirT           0\n","DAF_TD         0\n","DAF_SD         0\n","WFPS25cm       0\n","NH4            0\n","NO3            0\n","Clay           0\n","Sand           0\n","SOM            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Date</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Year</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Experiment</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DataUse</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Replication</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Month</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Vegetation</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>VegType</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>N2O</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>N_rate</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>PP2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>PP7</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AirT</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DAF_TD</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DAF_SD</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>WFPS25cm</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>NH4</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>NO3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Clay</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Sand</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>SOM</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":7}],"source":["# List of columns to impute missing values with the mean\n","columns_to_impute = ['N2O', 'N_rate', 'AirT', 'WFPS25cm', 'NO3', 'NH4', 'Clay', 'Sand']\n","\n","# Loop through each column and fill NaN with the mean of the respective column\n","for column in columns_to_impute:\n","    data.loc[:, column] = data[column].fillna(data[column].mean())\n","\n","\n","# Verify that there are no missing values left\n","missing_values_after_imputation = data.isna().sum()\n","missing_values_after_imputation\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"me_lLqPzzh7s","outputId":"21ea0b56-19a1-4be3-f160-b33b06889784","executionInfo":{"status":"ok","timestamp":1729491949215,"user_tz":-420,"elapsed":1084,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'01.Dataset-Rofiqul/BeforeRemoveOutliers/001.input_NaN_mean_agriculture_dataset.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["# Save the cleaned dataset to a new CSV file\n","output_file_path = '01.Dataset-Rofiqul/BeforeRemoveOutliers/001.input_NaN_mean_agriculture_dataset.csv'\n","data.to_csv(output_file_path, index=False)\n","\n","output_file_path"]},{"cell_type":"markdown","metadata":{"id":"20-tcycQ8NOh"},"source":["## Detect NaN Value"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"gn8lvAlk8NOh","outputId":"01588ea8-9958-4e7b-95cb-c1ed8191162d","colab":{"base_uri":"https://localhost:8080/","height":742},"executionInfo":{"status":"ok","timestamp":1729491949215,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date           0\n","Year           0\n","Experiment     0\n","DataUse        0\n","Replication    0\n","Month          0\n","Vegetation     0\n","VegType        0\n","N2O            0\n","N_rate         0\n","PP2            0\n","PP7            0\n","AirT           0\n","DAF_TD         0\n","DAF_SD         0\n","WFPS25cm       0\n","NH4            0\n","NO3            0\n","Clay           0\n","Sand           0\n","SOM            0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Date</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Year</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Experiment</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DataUse</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Replication</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Month</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Vegetation</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>VegType</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>N2O</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>N_rate</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>PP2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>PP7</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AirT</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DAF_TD</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DAF_SD</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>WFPS25cm</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>NH4</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>NO3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Clay</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Sand</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>SOM</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":9}],"source":["missing_values_count = data.isna().sum()\n","missing_values_count"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"s00x6-hm8NOh","outputId":"279353c0-c55c-4155-b1f7-1d79f998f6e2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729491949216,"user_tz":-420,"elapsed":5,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2246 entries, 0 to 2245\n","Data columns (total 21 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Date         2246 non-null   object \n"," 1   Year         2246 non-null   int64  \n"," 2   Experiment   2246 non-null   object \n"," 3   DataUse      2246 non-null   object \n"," 4   Replication  2246 non-null   object \n"," 5   Month        2246 non-null   object \n"," 6   Vegetation   2246 non-null   object \n"," 7   VegType      2246 non-null   object \n"," 8   N2O          2246 non-null   float64\n"," 9   N_rate       2246 non-null   int64  \n"," 10  PP2          2246 non-null   float64\n"," 11  PP7          2246 non-null   float64\n"," 12  AirT         2246 non-null   float64\n"," 13  DAF_TD       2246 non-null   int64  \n"," 14  DAF_SD       2246 non-null   int64  \n"," 15  WFPS25cm     2246 non-null   float64\n"," 16  NH4          2246 non-null   float64\n"," 17  NO3          2246 non-null   float64\n"," 18  Clay         2246 non-null   float64\n"," 19  Sand         2246 non-null   float64\n"," 20  SOM          2246 non-null   float64\n","dtypes: float64(10), int64(4), object(7)\n","memory usage: 368.6+ KB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{"id":"Uy1jmKkI0QNZ"},"source":["## StandartScaler"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cEc-iZpu0OrQ","outputId":"fda8c800-3fe8-4299-e785-175921a14351","executionInfo":{"status":"ok","timestamp":1729491949967,"user_tz":-420,"elapsed":755,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(      Date      Year Experiment   DataUse Replication     Month Vegetation  \\\n"," 0   2/9/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 1  2/10/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 2  2/18/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 3  2/19/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 4  3/16/12  0.020682   BCSE_KBS  Building          R1     March       Corn   \n"," \n","   VegType       N2O    N_rate  ...       PP7      AirT    DAF_TD    DAF_SD  \\\n"," 0  Annual -0.125408  0.481233  ... -0.811416 -1.518617  0.556855  0.294676   \n"," 1  Annual -0.185324  0.481233  ... -0.811416 -1.560776  0.563758  0.301675   \n"," 2  Annual -0.137842  0.481233  ... -0.447138 -1.276207  0.618974  0.357667   \n"," 3  Annual -0.144855  0.481233  ... -0.468640 -1.708330  0.625877  0.364667   \n"," 4  Annual -0.158726  0.481233  ... -0.457678  0.547142  0.805331  0.546643   \n"," \n","    WFPS25cm       NH4       NO3      Clay      Sand       SOM  \n"," 0  0.797637 -0.031188 -0.083017 -0.904182  0.796768 -0.642242  \n"," 1  0.645128 -0.034134 -0.082259 -0.904182  0.796768 -0.642242  \n"," 2  1.160223 -0.047719 -0.071667 -0.904182  0.796768 -0.642242  \n"," 3  0.917547 -0.046323 -0.069647 -0.904182  0.796768 -0.642242  \n"," 4  1.090364 -0.095994 -0.031903 -0.904182  0.796768 -0.642242  \n"," \n"," [5 rows x 21 columns],\n"," '01.Dataset-Rofiqul/BeforeRemoveOutliers/002.standard_scaler_agriculture_dataset.csv')"]},"metadata":{},"execution_count":11}],"source":["# Initialize the StandardScaler\n","scaler = StandardScaler()\n","\n","# Apply StandardScaler to the numerical columns\n","numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n","data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n","\n","# Save the scaled dataset to a new CSV file\n","scaled_output_file_path = '01.Dataset-Rofiqul/BeforeRemoveOutliers/002.standard_scaler_agriculture_dataset.csv'\n","data.to_csv(scaled_output_file_path, index=False)\n","\n","# Display the head of the scaled dataset\n","scaled_data_head = data.head()\n","scaled_data_head, scaled_output_file_path"]},{"cell_type":"markdown","source":["## IQR Detect Outlier for Groundtruth"],"metadata":{"id":"wg0puxu2M_3A"}},{"cell_type":"code","source":["# \"\"\"## IQR Outlier Detection and Groundtruth Creation\"\"\"\n","\n","# # Function to calculate IQR bounds\n","# def iqr_bounds(series):\n","#     Q1 = series.quantile(0.25)\n","#     Q3 = series.quantile(0.75)\n","#     IQR = Q3 - Q1\n","#     lower_bound = Q1 - 1.5 * IQR\n","#     upper_bound = Q3 + 1.5 * IQR\n","#     return lower_bound, upper_bound\n","\n","# # Detect outliers and create summary table\n","# summary_table = []\n","# groundtruth = pd.DataFrame(index=data.index)  # To store outliers\n","\n","# for col in numerical_columns:\n","#     lower_bound_IQR, upper_bound_IQR = iqr_bounds(data[col])\n","\n","#     # Detect outliers\n","#     outliers_IQR = (data[col] < lower_bound_IQR) | (data[col] > upper_bound_IQR)\n","\n","#     # Store the outlier information in the 'groundtruth' dataframe\n","#     groundtruth[col + '_outlier'] = outliers_IQR.astype(int)  # 1 for outlier, 0 for non-outlier\n","\n","#     # Append information to summary table\n","#     summary_table.append({\n","#         'Column': col,\n","#         'Method': 'IQR',\n","#         'Lower Bound': lower_bound_IQR,\n","#         'Upper Bound': upper_bound_IQR,\n","#         'Outlier Count': outliers_IQR.sum()\n","#     })\n","\n","# # Convert the summary table into a DataFrame for review\n","# summary_df = pd.DataFrame(summary_table)\n","# print(\"Outlier Summary IQR:\\n\", summary_df)\n","\n","# # Create the Groundtruth column by checking if there is any outlier in any column\n","# groundtruth['Groundtruth'] = groundtruth.any(axis=1).astype(int)  # 1 if outlier in any column, 0 if not\n","\n","# # Add the groundtruth to the original data (not scaled)\n","# data_with_groundtruth = pd.concat([data, groundtruth['Groundtruth']], axis=1)\n","\n","# # Save the dataset with Groundtruth column\n","# groundtruth_output_file_path = '01.Dataset-Rofiqul/BeforeRemoveOutliers/003.groundtruth_agriculture_dataset.csv'\n","# data_with_groundtruth.to_csv(groundtruth_output_file_path, index=False)\n","\n","# print(\"Groundtruth dataset saved at:\", groundtruth_output_file_path)\n","# # Example outlier detection using IQR (Interquartile Range)\n","# Q1 = data['N2O'].quantile(0.25)\n","# Q3 = data['N2O'].quantile(0.75)\n","# IQR = Q3 - Q1\n","# lower_bound = Q1 - 1.5 * IQR\n","# upper_bound = Q3 + 1.5 * IQR\n","\n","# # Define GroundTruth based on IQR\n","# data['GroundTruth'] = np.where((data['N2O'] < lower_bound) | (data['N2O'] > upper_bound), -1, 1)\n","\n","# # Select features for model input (X) and GroundTruth as the label (y)\n","# X = data[['N2O', 'N_rate', 'AirT', 'WFPS25cm', 'NO3', 'NH4', 'Clay', 'Sand']]  # Selected features\n","# y = data['GroundTruth']  # GroundTruth as the label (-1 for outlier, 1 for inlier)\n","\n","# # Split data into train and test sets\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# # Verify the shapes of the training and testing sets\n","# print(\"X_train shape:\", X_train.shape)\n","# print(\"y_train shape:\", y_train.shape)\n","# print(\"X_test shape:\", X_test.shape)\n","# print(\"y_test shape:\", y_test.shape)\n","\n","# # Save the dataset with the GroundTruth column\n","# groundtruth_output_file_path = '01.Dataset-Rofiqul/BeforeRemoveOutliers/003.groundtruth_agriculture_dataset.csv'\n","# data.to_csv(groundtruth_output_file_path, index=False)\n","\n","# print(\"Groundtruth dataset saved at:\", groundtruth_output_file_path)\n","\n","# # Create a summary DataFrame to show counts of inliers and outliers\n","# summary_df = pd.DataFrame({\n","#     'Inliers (1)': [np.sum(data['GroundTruth'] == 1)],\n","#     'Outliers (-1)': [np.sum(data['GroundTruth'] == -1)]\n","# })\n","\n","# # Display the summary of inliers and outliers\n","# print(\"Summary of GroundTruth labels:\")\n","# print(summary_df)\n","\n","## N2O Only\n","# Extract the N2O column\n","N2O_data = data['N2O']\n","\n","# Detect outliers using IQR method\n","Q1 = N2O_data.quantile(0.25)\n","Q3 = N2O_data.quantile(0.75)\n","IQR = Q3 - Q1\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","\n","# Define GroundTruth based on IQR only for N2O\n","data['GroundTruth'] = np.where((N2O_data < lower_bound) | (N2O_data > upper_bound), -1, 1)\n","\n","# Select features for model input (X) and GroundTruth as the label (y)\n","# X = data[['N_rate', 'AirT', 'WFPS25cm', 'NO3', 'NH4', 'Clay', 'Sand']]  # Use only non-N2O features\n","X = data[['N2O']]  # Use only non-N2O features\n","y = data['GroundTruth']  # GroundTruth as the label (-1 for outlier, 1 for inlier)\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Verify the shapes of the training and testing sets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","# Save the dataset with the GroundTruth column\n","groundtruth_output_file_path = '01.Dataset-Rofiqul/BeforeRemoveOutliers/003.groundtruth_agriculture_dataset.csv'\n","data.to_csv(groundtruth_output_file_path, index=False)\n","\n","print(\"Groundtruth dataset saved at:\", groundtruth_output_file_path)\n","\n","# Create a summary DataFrame to show counts of inliers and outliers\n","summary_df = pd.DataFrame({\n","    'Inliers (1)': [np.sum(data['GroundTruth'] == 1)],\n","    'Outliers (-1)': [np.sum(data['GroundTruth'] == -1)]\n","})\n","\n","# Display the summary of inliers and outliers\n","print(\"Summary of GroundTruth labels:\")\n","print(summary_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lLzCsqmNEN3","outputId":"cd2a1fd9-1b3c-4ddd-d47c-2ce9df7a6d88","executionInfo":{"status":"ok","timestamp":1729491950370,"user_tz":-420,"elapsed":404,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (1572, 1)\n","y_train shape: (1572,)\n","X_test shape: (674, 1)\n","y_test shape: (674,)\n","Groundtruth dataset saved at: 01.Dataset-Rofiqul/BeforeRemoveOutliers/003.groundtruth_agriculture_dataset.csv\n","Summary of GroundTruth labels:\n","   Inliers (1)  Outliers (-1)\n","0         1995            251\n"]}]},{"cell_type":"markdown","source":["# Isolation Forest"],"metadata":{"id":"QhkwmYinQO8p"}},{"cell_type":"code","source":["# Train and predict using Isolation Forest\n","iso_forest = IsolationForest(contamination=0.06, random_state=42)\n","\n","\n","iso_forest.fit(X_train)\n","y_pred_if = iso_forest.predict(X_test)\n","\n","# Performance Evaluation for Isolation Forest\n","\n","# Evaluate Isolation Forest using the IQR-based GroundTruth\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","precision_if = precision_score(y_test, y_pred_if, pos_label=-1)\n","recall_if = recall_score(y_test, y_pred_if, pos_label=-1)\n","f1_if = f1_score(y_test, y_pred_if, pos_label=-1)\n","\n","# Display performance metrics for Isolation Forest\n","print(\"Performance Metrics for Isolation Forest (using GroundTruth from IQR):\")\n","print(f\"Accuracy: {accuracy_if:.2f}\")\n","print(f\"Precision: {precision_if:.2f}\")\n","print(f\"Recall: {recall_if:.2f}\")\n","print(f\"F1-Score: {f1_if:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmlIOVx5QSLQ","executionInfo":{"status":"ok","timestamp":1729496997906,"user_tz":-420,"elapsed":924,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"0a6b62fb-e4f8-4ad4-d6c9-0babbae48cb4"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Performance Metrics for Isolation Forest (using GroundTruth from IQR):\n","Accuracy: 0.94\n","Precision: 0.83\n","Recall: 0.49\n","F1-Score: 0.62\n"]}]},{"cell_type":"markdown","source":["#DBScan"],"metadata":{"id":"n7g1rPwYSzeB"}},{"cell_type":"code","source":["# Train and predict using DBSCAN\n","dbscan = DBSCAN(eps=0.5, min_samples=2)\n","y_pred_db = dbscan.fit_predict(X_test)\n","\n","# Convert DBSCAN predictions to binary (outliers = -1, inliers = 1)\n","y_pred_db_binary = np.where(y_pred_db == -1, -1, 1)\n","\n","# Evaluate DBSCAN (using binary labels)\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","precision_db = precision_score(y_test, y_pred_db_binary, pos_label=-1)\n","recall_db = recall_score(y_test, y_pred_db_binary, pos_label=-1)\n","f1_db = f1_score(y_test, y_pred_db_binary, pos_label=-1)\n","\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-MkIGyBS1cQ","executionInfo":{"status":"ok","timestamp":1729496995277,"user_tz":-420,"elapsed":630,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"e294c9e8-8490-4399-a12b-c211b121e90c"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["DBSCAN           - Accuracy: 0.90, Precision: 1.00, Recall: 0.03, F1-Score: 0.06\n"]}]},{"cell_type":"markdown","source":["# One Class SVM"],"metadata":{"id":"Cw5zqKDQTGVf"}},{"cell_type":"code","source":["# Train and predict using One-Class SVM\n","ocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='auto')\n","# ocsvm = OneClassSVM(nu=0.5, kernel='linear', gamma=0.01)\n","y_pred_svm = ocsvm.fit_predict(X_test)\n","\n","# Evaluate One-Class SVM\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","precision_svm = precision_score(y_test, y_pred_svm, pos_label=-1)\n","recall_svm = recall_score(y_test, y_pred_svm, pos_label=-1)\n","f1_svm = f1_score(y_test, y_pred_svm, pos_label=-1)\n","\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvyjXCmZTH9x","executionInfo":{"status":"ok","timestamp":1729496998497,"user_tz":-420,"elapsed":2,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"5e63f266-9bbc-42b0-b868-1c358fdd9966"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["One-Class SVM    - Accuracy: 0.92, Precision: 0.72, Recall: 0.38, F1-Score: 0.50\n"]}]},{"cell_type":"markdown","source":["# Display Performance for each model"],"metadata":{"id":"7G9X-52NTYb4"}},{"cell_type":"code","source":["# Display performance metrics for each model\n","print(\"Performance Metrics for Individual Models:\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AHOGmA_TcDP","executionInfo":{"status":"ok","timestamp":1729497002047,"user_tz":-420,"elapsed":342,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"0a903fe3-12f9-446d-88cd-4762da0a8a47"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Performance Metrics for Individual Models:\n","Isolation Forest - Accuracy: 0.94, Precision: 0.83, Recall: 0.49, F1-Score: 0.62\n","DBSCAN           - Accuracy: 0.90, Precision: 1.00, Recall: 0.03, F1-Score: 0.06\n","One-Class SVM    - Accuracy: 0.92, Precision: 0.72, Recall: 0.38, F1-Score: 0.50\n"]}]},{"cell_type":"markdown","source":["# Ensemble (Manual)"],"metadata":{"id":"YglqO2sST6aQ"}},{"cell_type":"code","source":["# Combine the predictions using majority voting\n","\n","# Collect predictions from all models\n","predictions = np.vstack([y_pred_if, y_pred_db_binary, y_pred_svm]).T\n","\n","# Majority voting (mode of predictions)\n","y_pred_ensemble_majority = stats.mode(predictions, axis=1)[0].flatten()\n","\n","# Evaluate the majority voting ensemble's performance\n","accuracy_majority = accuracy_score(y_test, y_pred_ensemble_majority)\n","error_rate_majority = 1 - accuracy_majority\n","precision_majority = precision_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","recall_majority = recall_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","f1_majority = f1_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Majority Voting Ensemble:\")\n","print(f\"Majority Voting - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","\n","# Weighted Voting\n","# Assign weights to the models (you can adjust these based on individual model performance)\n","# weights = [0.5, 0.1, 0.4]  # Example: 40% for Isolation Forest, 30% for DBSCAN, 30% for One-Class SVM\n","weights = [0.4, 0.3, 0.3]  # Example: 40% for Isolation Forest, 30% for DBSCAN, 30% for One-Class SVM\n","\n","# Convert the predictions from (-1, 1) to (0, 1) for easier summing\n","predictions_binary = np.where(predictions == -1, 0, 1)\n","\n","# Perform weighted voting\n","weighted_sum = np.dot(predictions_binary, weights)\n","\n","# Setup threshold\n","threshold = 0.4\n","\n","# Convert weighted sum back to (-1, 1) labels: if sum >= 0.5, predict inlier (1); else outlier (-1)\n","y_pred_ensemble_weighted = np.where(weighted_sum >= threshold, 1, -1)\n","\n","# Evaluate the weighted voting ensemble's performance\n","accuracy_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n","error_rate_weighted = 1 - accuracy_weighted\n","precision_weighted = precision_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","recall_weighted = recall_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","f1_weighted = f1_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Weighted Voting Ensemble:\")\n","print(f\"Weighted Voting - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# Display performance comparison for all models and ensembles\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","error_rate_if = 1 - accuracy_if\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","error_rate_db = 1 - accuracy_db\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","error_rate_svm = 1 - accuracy_svm\n","\n","print(\"\\nPerformance Metrics for Individual Models, Majority Voting, and Weighted Voting:\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Error Rate: {error_rate_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Error Rate: {error_rate_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Error Rate: {error_rate_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","print(f\"Majority Voting  - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","print(f\"Weighted Voting  - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# # Check if the models are making diverse predictions\n","# agreement = np.sum(np.all(predictions == predictions[:, [0]], axis=1)) / len(predictions)\n","# print(f\"Percentage of total agreement between all models: {agreement * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEHooUIjT8DB","executionInfo":{"status":"ok","timestamp":1729497005331,"user_tz":-420,"elapsed":336,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"7faaa612-8c57-4765-8444-e9b2b87688b6"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Performance Metrics for Majority Voting Ensemble:\n","Majority Voting - Accuracy: 0.93, Error Rate: 0.07, Precision: 0.79, Recall: 0.38, F1-Score: 0.51\n","\n","Performance Metrics for Weighted Voting Ensemble:\n","Weighted Voting - Accuracy: 0.93, Error Rate: 0.07, Precision: 0.79, Recall: 0.38, F1-Score: 0.51\n","\n","Performance Metrics for Individual Models, Majority Voting, and Weighted Voting:\n","Isolation Forest - Accuracy: 0.94, Error Rate: 0.06, Precision: 0.83, Recall: 0.49, F1-Score: 0.62\n","DBSCAN           - Accuracy: 0.90, Error Rate: 0.10, Precision: 1.00, Recall: 0.03, F1-Score: 0.06\n","One-Class SVM    - Accuracy: 0.92, Error Rate: 0.08, Precision: 0.72, Recall: 0.38, F1-Score: 0.50\n","Majority Voting  - Accuracy: 0.93, Error Rate: 0.07, Precision: 0.79, Recall: 0.38, F1-Score: 0.51\n","Weighted Voting  - Accuracy: 0.93, Error Rate: 0.07, Precision: 0.79, Recall: 0.38, F1-Score: 0.51\n"]}]},{"cell_type":"markdown","source":["# XGBoost Prediction"],"metadata":{"id":"1V2HNmcRm96i"}},{"cell_type":"code","source":["# # --- Prediksi XGBoost ---\n","\n","# # Fungsi untuk menghitung metrik evaluasi\n","# def evaluate_model(y_true, y_pred):\n","#     mse = mean_squared_error(y_true, y_pred)\n","#     rmse = np.sqrt(mse)\n","#     mae = mean_absolute_error(y_true, y_pred)\n","#     r2 = r2_score(y_true, y_pred)\n","#     return mse, rmse, mae, r2\n","\n","# # --- Gunakan prediksi weighted voting untuk menentukan data inliers ---\n","# inliers_mask_test = y_pred_ensemble_weighted == 1  # Inliers adalah yang diprediksi sebagai 1 di X_test\n","\n","# # Pastikan N2O tidak digunakan sebagai fitur input\n","# X_inliers_test = X_test[inliers_mask_test].drop(columns=['N2O'])  # Hapus kolom N2O dari fitur input\n","# y_inliers_test = X_test[inliers_mask_test]['N2O']  # Target adalah kolom N2O\n","\n","# # --- Split data inliers menjadi training dan testing set untuk model XGBoost ---\n","# X_train_inliers, X_test_inliers, y_train_inliers, y_test_inliers = train_test_split(X_inliers_test, y_inliers_test, test_size=0.3, random_state=42)\n","\n","# # --- Inisialisasi dan latih model XGBoost ---\n","# xg_reg = XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n","#                       max_depth=5, alpha=10, n_estimators=100)\n","\n","# xg_reg.fit(X_train_inliers, y_train_inliers)\n","\n","# # --- Prediksi N2O pada data testing ---\n","# y_pred_xgb = xg_reg.predict(X_test_inliers)\n","\n","# # --- Evaluasi hasil prediksi ---\n","# mse, rmse, mae, r2 = evaluate_model(y_test_inliers, y_pred_xgb)\n","\n","# # Cetak metrik evaluasi regresi\n","# print(\"\\nEvaluation Metrics for XGBoost Regressor on N2O Emissions:\")\n","# print(f\"R-squared (R2): {r2:.2f}\")\n","# print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n","# print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n","# print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n","\n","# --- Prediksi XGBoost ---\n","\n","# Fungsi untuk menghitung metrik evaluasi\n","def evaluate_model(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    return mse, rmse, mae, r2\n","\n","# --- Gunakan prediksi weighted voting untuk menentukan data inliers ---\n","inliers_mask_test = y_pred_ensemble_weighted == 1  # Inliers adalah yang diprediksi sebagai 1 di X_test\n","X_inliers_test = X_test[inliers_mask_test]  # Data yang tidak terdeteksi sebagai outliers di X_test\n","y_inliers_test = y_test[inliers_mask_test]  # Hanya prediksi N2O untuk data inliers di X_test\n","\n","# --- Split data inliers menjadi training dan testing set untuk model XGBoost ---\n","X_train_inliers, X_test_inliers, y_train_inliers, y_test_inliers = train_test_split(X_inliers_test, y_inliers_test, test_size=0.3, random_state=42)\n","\n","# --- Inisialisasi dan latih model XGBoost ---\n","xg_reg = XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n","                      max_depth=5, alpha=10, n_estimators=100)\n","\n","xg_reg.fit(X_train_inliers, y_train_inliers)\n","\n","# --- Prediksi N2O pada data testing ---\n","y_pred_xgb = xg_reg.predict(X_test_inliers)\n","\n","# --- Evaluasi hasil prediksi ---\n","mse, rmse, mae, r2 = evaluate_model(y_test_inliers, y_pred_xgb)\n","\n","# Cetak metrik evaluasi regresi\n","print(\"\\nEvaluation Metrics for XGBoost Regressor on N2O Emissions:\")\n","print(f\"R-squared (R2): {r2:.2f}\")\n","print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n","print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n","print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aj88-z_rnBt7","executionInfo":{"status":"ok","timestamp":1729492330336,"user_tz":-420,"elapsed":335,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"51b84c89-ca71-46bc-c8d9-f22cbdd90279"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics for XGBoost Regressor on N2O Emissions:\n","R-squared (R2): 0.96\n","Mean Absolute Error (MAE): 0.04\n","Mean Squared Error (MSE): 0.01\n","Root Mean Squared Error (RMSE): 0.07\n"]}]},{"cell_type":"markdown","source":["# KFold Validation"],"metadata":{"id":"r12XoNVVtRNu"}},{"cell_type":"code","source":["# KFold XGBoost\n","def kfold_xgboost(X_train, y_train):\n","    params = {\n","        'objective': 'reg:squarederror',\n","        'learning_rate': 0.1,\n","        'max_depth': 5,\n","        'alpha': 10,\n","        'colsample_bytree': 0.3\n","    }\n","    dtrain = DMatrix(X_train, label=y_train)\n","\n","    # 5-fold cross-validation menggunakan num_boost_round\n","    cv_results = xgb.cv(dtrain=dtrain, params=params, nfold=5, num_boost_round=100,\n","                        metrics=['rmse', 'mae'], as_pandas=True, seed=42)\n","\n","    return cv_results\n","\n","# Prepare an empty dictionary to store results\n","results = {\n","    \"Test Size\": [],\n","    \"CV MSE\": [],\n","    \"MSE\": [],\n","    \"RMSE\": [],\n","    \"MAE\": [],\n","    \"R2\": []\n","}\n","\n","# Simulasi pengujian dengan berbagai test sizes (20%, 25%, 30%, 35%)\n","test_sizes = [0.2, 0.25, 0.3, 0.35]\n","\n","for test_size in test_sizes:\n","    # Split data into train and test sets\n","    X_train_inliers, X_test_inliers, y_train_inliers, y_test_inliers = train_test_split(X_inliers_test, y_inliers_test, test_size=test_size, random_state=42)\n","\n","    # Train the XGBoost model\n","    xg_reg = XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n","                          max_depth=5, alpha=10, n_estimators=100)\n","    xg_reg.fit(X_train_inliers, y_train_inliers)\n","\n","    # Predict the test data\n","    y_pred_xgb = xg_reg.predict(X_test_inliers)\n","\n","    # Evaluate predictions\n","    mse, rmse, mae, r2 = evaluate_model(y_test_inliers, y_pred_xgb)\n","\n","    # --- KFold Cross-Validation ---\n","    kfold_results = kfold_xgboost(X_train_inliers, y_train_inliers)\n","    mse_cv = kfold_results['test-rmse-mean'].values[-1] ** 2\n","    rmse_cv = np.sqrt(mse_cv)\n","\n","    # Store the results for this test size\n","    results[\"Test Size\"].append(f\"{int(test_size*100)}%\")\n","    results[\"CV MSE\"].append(round(mse_cv, 4))\n","    results[\"MSE\"].append(round(mse, 4))\n","    results[\"RMSE\"].append(round(rmse, 4))\n","    results[\"MAE\"].append(round(mae, 4))\n","    results[\"R2\"].append(round(r2, 4))\n","\n","# Convert results to DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Display the DataFrame as a text-based table (easily copyable)\n","results_df\n","print(\"\\nPrediction Evaluation with KFold XGBoost\")\n","print(results_df.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxIDmx-vtTO1","executionInfo":{"status":"ok","timestamp":1729492336704,"user_tz":-420,"elapsed":1187,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"12688286-1b6b-4f21-c129-94b7f1db9bc8"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Prediction Evaluation with KFold XGBoost\n","Test Size  CV MSE    MSE   RMSE    MAE     R2\n","      20%  0.0216 0.0060 0.0777 0.0363 0.9664\n","      25%  0.0138 0.0050 0.0706 0.0347 0.9657\n","      30%  0.0284 0.0056 0.0750 0.0369 0.9604\n","      35%  0.0236 0.0056 0.0748 0.0385 0.9597\n"]}]},{"cell_type":"markdown","source":["# Standart Cross Validation"],"metadata":{"id":"daGUjdpV27kW"}},{"cell_type":"code","source":["import pandas as pd\n","from tabulate import tabulate\n","\n","# Fungsi untuk Standard Cross-Validation dengan cross_val_score\n","def standard_cross_validation(X_train, y_train):\n","    xg_reg = XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n","                          max_depth=5, alpha=10, n_estimators=100)\n","\n","    # 5-fold cross-validation\n","    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    # Mean Squared Error\n","    mse_scores = cross_val_score(xg_reg, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n","    mae_scores = cross_val_score(xg_reg, X_train, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n","    r2_scores = cross_val_score(xg_reg, X_train, y_train, cv=kfold, scoring='r2')\n","\n","    # Take the mean and convert negative MSE and MAE to positive\n","    mse_mean = -np.mean(mse_scores)\n","    rmse_mean = np.sqrt(mse_mean)\n","    mae_mean = -np.mean(mae_scores)\n","    r2_mean = np.mean(r2_scores)\n","\n","    return mse_mean, rmse_mean, mae_mean, r2_mean\n","\n","# Prepare an empty dictionary to store results\n","results_standard_cv = {\n","    \"Test Size\": [],\n","    \"CV MSE\": [],\n","    \"MSE\": [],\n","    \"RMSE\": [],\n","    \"MAE\": [],\n","    \"R\": []\n","}\n","\n","# Simulasi pengujian dengan berbagai test sizes (20%, 25%, 30%, 35%)\n","test_sizes = [0.2, 0.25, 0.3, 0.35]\n","\n","for test_size in test_sizes:\n","    # Split data into train and test sets\n","    X_train_inliers, X_test_inliers, y_train_inliers, y_test_inliers = train_test_split(X_inliers_test, y_inliers_test, test_size=test_size, random_state=42)\n","\n","    # Train the XGBoost model\n","    xg_reg = XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n","                          max_depth=5, alpha=10, n_estimators=100)\n","    xg_reg.fit(X_train_inliers, y_train_inliers)\n","\n","    # Predict the test data\n","    y_pred_xgb = xg_reg.predict(X_test_inliers)\n","\n","    # Evaluate predictions\n","    mse, rmse, mae, r2 = evaluate_model(y_test_inliers, y_pred_xgb)\n","\n","    # --- Standard Cross-Validation ---\n","    mse_cv, rmse_cv, mae_cv, r2_cv = standard_cross_validation(X_train_inliers, y_train_inliers)\n","\n","    # Store the results for this test size\n","    results_standard_cv[\"Test Size\"].appen(f\"{int(test_size*100)}%\")\n","    results_standard_cv[\"CV MSE\"].append(round(mse_cv, 4))\n","    results_standard_cv[\"MSE\"].append(round(mse, 4))\n","    results_standard_cv[\"RMSE\"].append(round(rmse, 4))\n","    results_standard_cv[\"MAE\"].append(round(mae, 4))\n","    results_standard_cv[\"R\"].append(round(r2, 4))\n","\n","# Convert results to DataFrame\n","results_standard_cv_df = pd.DataFrame(results_standard_cv)\n","\n","# Display the DataFrame as a formatted table\n","table_str = tabulate(results_standard_cv_df, headers='keys', tablefmt='grid', showindex=False)\n","print(\"\\nPrediction Evaluation with Standard Cross-Validation\")\n","print(table_str)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwfSl3Di3Alt","executionInfo":{"status":"ok","timestamp":1729492348498,"user_tz":-420,"elapsed":2285,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}},"outputId":"f8d5f6e7-6c95-4741-9524-1a2cb519acaa"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Prediction Evaluation with Standard Cross-Validation\n","+-------------+----------+--------+--------+--------+--------+\n","| Test Size   |   CV MSE |    MSE |   RMSE |    MAE |     R |\n","+=============+==========+========+========+========+========+\n","| 20%         |   0.0304 | 0.006  | 0.0777 | 0.0363 | 0.9664 |\n","+-------------+----------+--------+--------+--------+--------+\n","| 25%         |   0.0143 | 0.005  | 0.0706 | 0.0347 | 0.9657 |\n","+-------------+----------+--------+--------+--------+--------+\n","| 30%         |   0.04   | 0.0056 | 0.075  | 0.0369 | 0.9604 |\n","+-------------+----------+--------+--------+--------+--------+\n","| 35%         |   0.0271 | 0.0056 | 0.0748 | 0.0385 | 0.9597 |\n","+-------------+----------+--------+--------+--------+--------+\n"]}]},{"cell_type":"markdown","source":["# GridSearchCV"],"metadata":{"id":"fxvATbVF6sS0"}},{"cell_type":"code","source":["# Set hyperparameters for tuning\n","param_grid = {\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'max_depth': [3, 5, 7],\n","    'n_estimators': [100, 200],\n","    'subsample': [0.8, 1.0],\n","    'colsample_bytree': [0.6, 0.8]\n","}\n","\n","# Simulasi pengujian dengan berbagai test sizes (20%, 25%, 30%, 35%)\n","test_sizes = [0.2, 0.25, 0.3, 0.35]\n","\n","# Prepare an empty dictionary to store results\n","results = {\n","    \"Test Size\": [],\n","    \"CV MSE\": [],\n","    \"MSE\": [],\n","    \"RMSE\": [],\n","    \"MAE\": [],\n","    \"R\": []\n","}\n","\n","for test_size in test_sizes:\n","    # Split data into train and test sets\n","    X_train_inliers, X_test_inliers, y_train_inliers, y_test_inliers = train_test_split(X_inliers_test, y_inliers_test, test_size=test_size, random_state=42)\n","\n","    # Inisialisasi XGBoost Regressor\n","    xg_reg = XGBRegressor(objective='reg:squarederror')\n","\n","    # GridSearchCV untuk hyperparameter tuning\n","    grid_search = GridSearchCV(estimator=xg_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n","    grid_search.fit(X_train_inliers, y_train_inliers)\n","\n","    # Predict with the best model\n","    best_model = grid_search.best_estimator_\n","    y_pred_xgb = best_model.predict(X_test_inliers)\n","\n","    # Evaluasi hasil prediksi\n","    mse, rmse, mae, r2 = evaluate_model(y_test_inliers, y_pred_xgb)\n","\n","    # Simpan hasil Cross-Validation MSE (dikonversi dari negatif)\n","    cv_mse = -grid_search.best_score_\n","\n","    # Simpan hasil ke dictionary\n","    results[\"Test Size\"].append(f\"{int(test_size * 100)}%\")\n","    results[\"CV MSE\"].append(round(cv_mse, 4))\n","    results[\"MSE\"].append(round(mse, 4))\n","    results[\"RMSE\"].append(round(rmse, 4))\n","    results[\"MAE\"].append(round(mae, 4))\n","    results[\"R\"].append(round(r2, 4))\n","\n","# Konversi hasil ke dalam DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Tampilkan hasil sebagai tabel yang mudah dibaca\n","print(\"\\nPrediction Evaluation with XGBoost GridSearchCV Hyperparameter Tuning\")\n","print(results_df.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrW0xxDZ6xqT","outputId":"fd933b3a-c027-4e2f-97a7-ca9a77292c0a","executionInfo":{"status":"ok","timestamp":1729492410305,"user_tz":-420,"elapsed":49039,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Prediction Evaluation with XGBoost GridSearchCV Hyperparameter Tuning\n","Test Size  CV MSE  MSE   RMSE    MAE     R\n","      20%  0.0034  0.0 0.0001 0.0000 1.0000\n","      25%  0.0080  0.0 0.0028 0.0012 0.9999\n","      30%  0.0090  0.0 0.0001 0.0000 1.0000\n","      35%  0.0096  0.0 0.0028 0.0013 0.9999\n"]}]},{"cell_type":"markdown","source":["#RandomizedSearchCV"],"metadata":{"id":"ykHZFU9oz9gb"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.model_selection import RandomizedSearchCV\n","import pandas as pd\n","from tabulate import tabulate\n","\n","# Set hyperparameters for tuning in RandomizedSearchCV\n","param_distributions = {\n","    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","    'max_depth': [3, 5, 7, 10],\n","    'n_estimators': [50, 100, 200],\n","    'subsample': [0.6, 0.8, 1.0],\n","    'colsample_bytree': [0.6, 0.8, 1.0],\n","    'gamma': [0, 0.1, 0.3, 0.5],\n","    'reg_alpha': [0, 0.01, 0.1],\n","    'reg_lambda': [0.01, 0.1, 1.0]\n","}\n","\n","# Prepare an empty dictionary to store RandomizedSearchCV results\n","results_random_search = {\n","    \"Test Size\": [],\n","    \"CV MSE\": [],\n","    \"MSE\": [],\n","    \"RMSE\": [],\n","    \"MAE\": [],\n","    \"R\": []\n","}\n","\n","# Simulasi pengujian dengan berbagai test sizes (20%, 25%, 30%, 35%)\n","test_sizes = [0.2, 0.25, 0.3, 0.35]\n","\n","for test_size in test_sizes:\n","    # Split data into train and test sets\n","    X_train_inliers, X_test_inliers, y_train_inliers, y_test_inliers = train_test_split(X_inliers_test, y_inliers_test, test_size=test_size, random_state=42)\n","\n","    # Inisialisasi XGBoost Regressor\n","    xg_reg = XGBRegressor(objective='reg:squarederror')\n","\n","    # RandomizedSearchCV untuk hyperparameter tuning\n","    random_search = RandomizedSearchCV(\n","        estimator=xg_reg,\n","        param_distributions=param_distributions,\n","        n_iter=50,  # Jumlah iterasi, dapat diatur lebih besar atau lebih kecil tergantung kebutuhan\n","        cv=5,  # 5-fold cross-validation\n","        scoring='neg_mean_squared_error',\n","        random_state=42,\n","        n_jobs=-1\n","    )\n","\n","    # Fit RandomizedSearchCV model\n","    random_search.fit(X_train_inliers, y_train_inliers)\n","\n","    # Predict with the best model found by RandomizedSearchCV\n","    best_model_random = random_search.best_estimator_\n","    y_pred_xgb_random = best_model_random.predict(X_test_inliers)\n","\n","    # Evaluasi hasil prediksi\n","    mse, rmse, mae, r2 = evaluate_model(y_test_inliers, y_pred_xgb_random)\n","\n","    # Simpan hasil Cross-Validation MSE (dikonversi dari negatif)\n","    cv_mse = -random_search.best_score_\n","\n","    # Simpan hasil ke dictionary\n","    results_random_search[\"Test Size\"].append(f\"{int(test_size * 100)}%\")\n","    results_random_search[\"CV MSE\"].append(round(cv_mse, 4))\n","    results_random_search[\"MSE\"].append(round(mse, 4))\n","    results_random_search[\"RMSE\"].append(round(rmse, 4))\n","    results_random_search[\"MAE\"].append(round(mae, 4))\n","    results_random_search[\"R\"].append(round(r2, 4))\n","\n","# Konversi hasil ke dalam DataFrame\n","results_random_search_df = pd.DataFrame(results_random_search)\n","\n","# Tampilkan hasil sebagai tabel yang mudah dibaca\n","print(\"\\nPrediction Evaluation with XGBoost RandomizedSearchCV Hyperparameter Tuning\")\n","print(results_random_search_df.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASLPcRkE0AaH","outputId":"6516b364-4d4f-4ee8-d943-a88239bb5bba","executionInfo":{"status":"ok","timestamp":1729492592497,"user_tz":-420,"elapsed":30449,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Prediction Evaluation with XGBoost RandomizedSearchCV Hyperparameter Tuning\n","Test Size  CV MSE    MSE   RMSE    MAE     R\n","      20%  0.0018 0.0002 0.0130 0.0056 0.9991\n","      25%  0.0045 0.0004 0.0212 0.0098 0.9969\n","      30%  0.0035 0.0001 0.0085 0.0028 0.9995\n","      35%  0.0080 0.0001 0.0119 0.0051 0.9990\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"14NCgtmwHNGLWJ2eUD8yjDHYfCXxuhmNx","timestamp":1729491864262},{"file_id":"1xtubTTvSW3YBrMFYjarTpwQIJ3PYLTVG","timestamp":1729444823147},{"file_id":"1vJhvTpTD3PhtaGxMW_n5Cetro-tiwIQ0","timestamp":1729313878490},{"file_id":"1vbBEsonBcBXmX52xLaImBBbGy0cpusr-","timestamp":1728013139100},{"file_id":"1M_85TxDI7JhjFXkmHyUeKBkpTccvcnt0","timestamp":1727407593051},{"file_id":"1tCNl-JcueGmNpD4OxRNyLuleUUXsMYH_","timestamp":1726220211340},{"file_id":"1bElswYxfkl4uI372RGL86wuwHZywTgJL","timestamp":1726140131893}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}