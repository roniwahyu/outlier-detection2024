{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18672,"status":"ok","timestamp":1729320471769,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"SG0c2_O1J8UJ","outputId":"65e73481-1db3-4123-e5ca-8a1e34e416fc"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1729320471770,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"NkIwO501KIhe","outputId":"2d3f07f6-9f70-4278-80bf-cf29d1314f58"},"outputs":[],"source":["# Path to google drive folder\n","# %cd /content/drive/MyDrive/Colab Notebooks/Disertasi-Ahmad-Rofiqul/002. Laporan-eksperimen\n","\n","# %cd /content/drive/MyDrive/Colab Notebooks/Disertasi-Ahmad-Rofiqul/002.Experiment_SWI_16052024/"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":15343,"status":"ok","timestamp":1729320487111,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"E3maRHbiKSMZ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import IsolationForest, RandomForestClassifier\n","from sklearn.cluster import DBSCAN\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import classification_report\n","from xgboost import XGBRegressor\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","from sklearn.svm import OneClassSVM\n","from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1729320487111,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"hSf0yMJ6-dxS","outputId":"5fe0fa97-ebc3-460f-98b8-c87f535ac17b"},"outputs":[],"source":["# !ls"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":779,"status":"ok","timestamp":1729320487888,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"cB3eaRnqKU1A","outputId":"24a8edf0-bb8c-4da3-fae0-d7595f049767"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2246 entries, 0 to 2245\n","Data columns (total 21 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Date         2246 non-null   object \n"," 1   Year         2246 non-null   int64  \n"," 2   Experiment   2246 non-null   object \n"," 3   DataUse      2246 non-null   object \n"," 4   Replication  2246 non-null   object \n"," 5   Month        2246 non-null   object \n"," 6   Vegetation   2246 non-null   object \n"," 7   VegType      2246 non-null   object \n"," 8   N2O          2246 non-null   float64\n"," 9   N_rate       2246 non-null   int64  \n"," 10  PP2          2246 non-null   float64\n"," 11  PP7          2246 non-null   float64\n"," 12  AirT         2246 non-null   float64\n"," 13  DAF_TD       2246 non-null   int64  \n"," 14  DAF_SD       2246 non-null   int64  \n"," 15  WFPS25cm     2194 non-null   float64\n"," 16  NH4          2170 non-null   float64\n"," 17  NO3          2216 non-null   float64\n"," 18  Clay         2246 non-null   float64\n"," 19  Sand         2246 non-null   float64\n"," 20  SOM          2246 non-null   float64\n","dtypes: float64(10), int64(4), object(7)\n","memory usage: 368.6+ KB\n"]},{"data":{"text/plain":["(      Date  Year Experiment   DataUse Replication     Month Vegetation  \\\n"," 0   2/9/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 1  2/10/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 2  2/18/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 3  2/19/12  2012   BCSE_KBS  Building          R1  February       Corn   \n"," 4  3/16/12  2012   BCSE_KBS  Building          R1     March       Corn   \n"," \n","   VegType       N2O  N_rate  ...   PP7  AirT  DAF_TD  DAF_SD  WFPS25cm  \\\n"," 0  Annual  3.896742     170  ...  0.00  -2.0     276     241  0.666508   \n"," 1  Annual  2.190218     170  ...  0.00  -2.4     277     242  0.640608   \n"," 2  Annual  3.542594     170  ...  8.64   0.3     285     250  0.728085   \n"," 3  Annual  3.342870     170  ...  8.13  -3.8     286     251  0.686872   \n"," 4  Annual  2.947778     170  ...  8.39  17.6     312     277  0.716221   \n"," \n","          NH4        NO3  Clay   Sand       SOM  \n"," 0  11.046340  22.940812  62.5  637.5  1.174072  \n"," 1  11.008087  22.959578  62.5  637.5  1.174072  \n"," 2  10.831669  23.221928  62.5  637.5  1.174072  \n"," 3  10.849792  23.271978  62.5  637.5  1.174072  \n"," 4  10.204748  24.206855  62.5  637.5  1.174072  \n"," \n"," [5 rows x 21 columns],\n"," None,\n","               Year          N2O       N_rate          PP2          PP7  \\\n"," count  2246.000000  2246.000000  2246.000000  2246.000000  2246.000000   \n"," mean   2011.925200     7.468610   142.994212     5.219839    19.245273   \n"," std       3.617418    28.488257    56.130412    10.064123    23.723416   \n"," min    2002.000000    -7.415297     0.000000     0.000000     0.000000   \n"," 25%    2011.000000     0.504316   135.000000     0.000000     3.560000   \n"," 50%    2013.000000     1.972058   170.000000     0.510000    11.930000   \n"," 75%    2014.000000     5.187618   170.000000     6.000000    27.000000   \n"," max    2017.000000   593.072000   213.000000    95.250000   260.090000   \n"," \n","               AirT       DAF_TD       DAF_SD     WFPS25cm          NH4  \\\n"," count  2246.000000  2246.000000  2246.000000  2194.000000  2170.000000   \n"," mean     12.408699   195.321015   198.898041     0.531047    11.451364   \n"," std       9.490152   144.915448   142.907436     0.171868    13.214895   \n"," min     -20.700000     1.000000     0.000000     0.024388     1.383393   \n"," 25%       5.940000    73.250000    75.000000     0.390203     5.290323   \n"," 50%      14.490000   160.000000   172.000000     0.553853     9.081282   \n"," 75%      20.070000   308.750000   320.000000     0.680321    12.140325   \n"," max      30.700000   718.000000   678.000000     0.912113   228.525000   \n"," \n","                NO3         Clay         Sand          SOM  \n"," count  2216.000000  2246.000000  2246.000000  2246.000000  \n"," mean     24.997063   134.425163   462.686739     1.901503  \n"," std      24.941785    79.564891   219.451957     1.132896  \n"," min       0.370070    62.500000    55.000000     1.174072  \n"," 25%      10.184722    62.500000   418.833333     1.174072  \n"," 50%      19.795863   128.333333   491.666667     1.186800  \n"," 75%      27.085459   183.250000   637.500000     1.823200  \n"," max     238.920000   280.000000   637.500000     4.500000  )"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Load the dataset\n","file_path = 'dataset/agriculture_dataset.csv'\n","data = pd.read_csv(file_path)\n","\n","# Display the first few rows of the dataset for review\n","data.head(),data.info(),data.describe()"]},{"cell_type":"markdown","metadata":{"id":"cvC5kqWgyvO3"},"source":["## Detect Nilai NaN"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":742},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1729320487888,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"gDng0fbFyr3m","outputId":"a024f1b8-d0f5-4026-85e9-c73b2cee2970"},"outputs":[{"data":{"text/plain":["Date            0\n","Year            0\n","Experiment      0\n","DataUse         0\n","Replication     0\n","Month           0\n","Vegetation      0\n","VegType         0\n","N2O             0\n","N_rate          0\n","PP2             0\n","PP7             0\n","AirT            0\n","DAF_TD          0\n","DAF_SD          0\n","WFPS25cm       52\n","NH4            76\n","NO3            30\n","Clay            0\n","Sand            0\n","SOM             0\n","dtype: int64"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["\n","missing_values_count = data.isna().sum()\n","missing_values_count"]},{"cell_type":"markdown","metadata":{"id":"yzcM1q5Ay_KD"},"source":["## Impute NaN or missing value with Mean"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":890},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1729320487889,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"cT6ViegGy-Xx","outputId":"e55cb529-710e-4b50-b481-183540243df6"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_23720\\1798400306.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data[column].fillna(data[column].mean(), inplace=True)\n"]},{"data":{"text/plain":["Date           0\n","Year           0\n","Experiment     0\n","DataUse        0\n","Replication    0\n","Month          0\n","Vegetation     0\n","VegType        0\n","N2O            0\n","N_rate         0\n","PP2            0\n","PP7            0\n","AirT           0\n","DAF_TD         0\n","DAF_SD         0\n","WFPS25cm       0\n","NH4            0\n","NO3            0\n","Clay           0\n","Sand           0\n","SOM            0\n","dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# List of columns to impute missing values with the mean\n","columns_to_impute = ['N2O', 'N_rate', 'AirT', 'WFPS25cm', 'NO3', 'NH4', 'Clay', 'Sand']\n","\n","# Loop through each column and fill NaN with the mean of the respective column\n","for column in columns_to_impute:\n","    data[column].fillna(data[column].mean(), inplace=True)\n","\n","# Verify that there are no missing values left\n","missing_values_after_imputation = data.isna().sum()\n","missing_values_after_imputation\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":925,"status":"ok","timestamp":1729320488810,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"me_lLqPzzh7s","outputId":"4e08e8a2-2951-462c-f56f-8582002808cb"},"outputs":[{"data":{"text/plain":["'hasil/BeforeRemoveOutliers/001.input_NaN_mean_agriculture_dataset.csv'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# Save the cleaned dataset to a new CSV file\n","output_file_path = 'hasil/BeforeRemoveOutliers/001.input_NaN_mean_agriculture_dataset.csv'\n","data.to_csv(output_file_path, index=False)\n","\n","output_file_path"]},{"cell_type":"markdown","metadata":{"id":"20-tcycQ8NOh"},"source":["## Detect NaN Value"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":742},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729320488810,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"gn8lvAlk8NOh","outputId":"16e45a0c-795b-4662-c8ea-3df8a0897df0"},"outputs":[{"data":{"text/plain":["Date           0\n","Year           0\n","Experiment     0\n","DataUse        0\n","Replication    0\n","Month          0\n","Vegetation     0\n","VegType        0\n","N2O            0\n","N_rate         0\n","PP2            0\n","PP7            0\n","AirT           0\n","DAF_TD         0\n","DAF_SD         0\n","WFPS25cm       0\n","NH4            0\n","NO3            0\n","Clay           0\n","Sand           0\n","SOM            0\n","dtype: int64"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["missing_values_count = data.isna().sum()\n","missing_values_count"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1729320488810,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"s00x6-hm8NOh","outputId":"fd1dc3be-4e34-4074-be94-96dc6253d724"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2246 entries, 0 to 2245\n","Data columns (total 21 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Date         2246 non-null   object \n"," 1   Year         2246 non-null   int64  \n"," 2   Experiment   2246 non-null   object \n"," 3   DataUse      2246 non-null   object \n"," 4   Replication  2246 non-null   object \n"," 5   Month        2246 non-null   object \n"," 6   Vegetation   2246 non-null   object \n"," 7   VegType      2246 non-null   object \n"," 8   N2O          2246 non-null   float64\n"," 9   N_rate       2246 non-null   int64  \n"," 10  PP2          2246 non-null   float64\n"," 11  PP7          2246 non-null   float64\n"," 12  AirT         2246 non-null   float64\n"," 13  DAF_TD       2246 non-null   int64  \n"," 14  DAF_SD       2246 non-null   int64  \n"," 15  WFPS25cm     2246 non-null   float64\n"," 16  NH4          2246 non-null   float64\n"," 17  NO3          2246 non-null   float64\n"," 18  Clay         2246 non-null   float64\n"," 19  Sand         2246 non-null   float64\n"," 20  SOM          2246 non-null   float64\n","dtypes: float64(10), int64(4), object(7)\n","memory usage: 368.6+ KB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{"id":"Uy1jmKkI0QNZ"},"source":["## StandartScaler"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":441,"status":"ok","timestamp":1729320489248,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"cEc-iZpu0OrQ","outputId":"12997b89-af5b-47f3-81b6-e15ec39c5341"},"outputs":[{"data":{"text/plain":["(      Date      Year Experiment   DataUse Replication     Month Vegetation  \\\n"," 0   2/9/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 1  2/10/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 2  2/18/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 3  2/19/12  0.020682   BCSE_KBS  Building          R1  February       Corn   \n"," 4  3/16/12  0.020682   BCSE_KBS  Building          R1     March       Corn   \n"," \n","   VegType       N2O    N_rate  ...       PP7      AirT    DAF_TD    DAF_SD  \\\n"," 0  Annual -0.125408  0.481233  ... -0.811416 -1.518617  0.556855  0.294676   \n"," 1  Annual -0.185324  0.481233  ... -0.811416 -1.560776  0.563758  0.301675   \n"," 2  Annual -0.137842  0.481233  ... -0.447138 -1.276207  0.618974  0.357667   \n"," 3  Annual -0.144855  0.481233  ... -0.468640 -1.708330  0.625877  0.364667   \n"," 4  Annual -0.158726  0.481233  ... -0.457678  0.547142  0.805331  0.546643   \n"," \n","    WFPS25cm       NH4       NO3      Clay      Sand       SOM  \n"," 0  0.797637 -0.031188 -0.083017 -0.904182  0.796768 -0.642242  \n"," 1  0.645128 -0.034134 -0.082259 -0.904182  0.796768 -0.642242  \n"," 2  1.160223 -0.047719 -0.071667 -0.904182  0.796768 -0.642242  \n"," 3  0.917547 -0.046323 -0.069647 -0.904182  0.796768 -0.642242  \n"," 4  1.090364 -0.095994 -0.031903 -0.904182  0.796768 -0.642242  \n"," \n"," [5 rows x 21 columns],\n"," 'hasil/BeforeRemoveOutliers/002.standard_scaler_agriculture_dataset.csv')"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize the StandardScaler\n","scaler = StandardScaler()\n","\n","# Apply StandardScaler to the numerical columns\n","numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n","data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n","\n","# Save the scaled dataset to a new CSV file\n","scaled_output_file_path = 'hasil/BeforeRemoveOutliers/002.standard_scaler_agriculture_dataset.csv'\n","data.to_csv(scaled_output_file_path, index=False)\n","\n","# Display the head of the scaled dataset\n","scaled_data_head = data.head()\n","scaled_data_head, scaled_output_file_path"]},{"cell_type":"markdown","metadata":{"id":"wg0puxu2M_3A"},"source":["## IQR Detect Outlier for Groundtruth"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1729320489664,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"5lLzCsqmNEN3","outputId":"afdf177b-f09a-4bbb-918d-bb4d3d48141d"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (1572, 8)\n","y_train shape: (1572,)\n","X_test shape: (674, 8)\n","y_test shape: (674,)\n","Groundtruth dataset saved at: hasil/BeforeRemoveOutliers/003.groundtruth_agriculture_dataset.csv\n","Summary of GroundTruth labels:\n","   Inliers (1)  Outliers (-1)\n","0         1995            251\n"]}],"source":["# \"\"\"## IQR Outlier Detection and Groundtruth Creation\"\"\"\n","\n","# # Function to calculate IQR bounds\n","# def iqr_bounds(series):\n","#     Q1 = series.quantile(0.25)\n","#     Q3 = series.quantile(0.75)\n","#     IQR = Q3 - Q1\n","#     lower_bound = Q1 - 1.5 * IQR\n","#     upper_bound = Q3 + 1.5 * IQR\n","#     return lower_bound, upper_bound\n","\n","# # Detect outliers and create summary table\n","# summary_table = []\n","# groundtruth = pd.DataFrame(index=data.index)  # To store outliers\n","\n","# for col in numerical_columns:\n","#     lower_bound_IQR, upper_bound_IQR = iqr_bounds(data[col])\n","\n","#     # Detect outliers\n","#     outliers_IQR = (data[col] < lower_bound_IQR) | (data[col] > upper_bound_IQR)\n","\n","#     # Store the outlier information in the 'groundtruth' dataframe\n","#     groundtruth[col + '_outlier'] = outliers_IQR.astype(int)  # 1 for outlier, 0 for non-outlier\n","\n","#     # Append information to summary table\n","#     summary_table.append({\n","#         'Column': col,\n","#         'Method': 'IQR',\n","#         'Lower Bound': lower_bound_IQR,\n","#         'Upper Bound': upper_bound_IQR,\n","#         'Outlier Count': outliers_IQR.sum()\n","#     })\n","\n","# # Convert the summary table into a DataFrame for review\n","# summary_df = pd.DataFrame(summary_table)\n","# print(\"Outlier Summary IQR:\\n\", summary_df)\n","\n","# # Create the Groundtruth column by checking if there is any outlier in any column\n","# groundtruth['Groundtruth'] = groundtruth.any(axis=1).astype(int)  # 1 if outlier in any column, 0 if not\n","\n","# # Add the groundtruth to the original data (not scaled)\n","# data_with_groundtruth = pd.concat([data, groundtruth['Groundtruth']], axis=1)\n","\n","# # Save the dataset with Groundtruth column\n","# groundtruth_output_file_path = 'hasil/BeforeRemoveOutliers_003.groundtruth_agriculture_dataset.csv'\n","# data_with_groundtruth.to_csv(groundtruth_output_file_path, index=False)\n","\n","# print(\"Groundtruth dataset saved at:\", groundtruth_output_file_path)\n","# Example outlier detection using IQR (Interquartile Range)\n","Q1 = data['N2O'].quantile(0.25)\n","Q3 = data['N2O'].quantile(0.75)\n","IQR = Q3 - Q1\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","\n","# Define GroundTruth based on IQR\n","data['GroundTruth'] = np.where((data['N2O'] < lower_bound) | (data['N2O'] > upper_bound), -1, 1)\n","\n","# Select features for model input (X) and GroundTruth as the label (y)\n","X = data[['N2O', 'N_rate', 'AirT', 'WFPS25cm', 'NO3', 'NH4', 'Clay', 'Sand']]  # Selected features\n","y = data['GroundTruth']  # GroundTruth as the label (-1 for outlier, 1 for inlier)\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Verify the shapes of the training and testing sets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","# Save the dataset with the GroundTruth column\n","groundtruth_output_file_path = 'hasil/BeforeRemoveOutliers/003.groundtruth_agriculture_dataset.csv'\n","data.to_csv(groundtruth_output_file_path, index=False)\n","\n","print(\"Groundtruth dataset saved at:\", groundtruth_output_file_path)\n","\n","# Create a summary DataFrame to show counts of inliers and outliers\n","summary_df = pd.DataFrame({\n","    'Inliers (1)': [np.sum(data['GroundTruth'] == 1)],\n","    'Outliers (-1)': [np.sum(data['GroundTruth'] == -1)]\n","})\n","\n","# Display the summary of inliers and outliers\n","print(\"Summary of GroundTruth labels:\")\n","print(summary_df)\n","# Save the dataset with the GroundTruth column\n","summarypath = 'hasil/BeforeRemoveOutliers/003.summary_groundtruth_agriculture_dataset.csv'\n","summary_df.to_csv(summarypath, index=False)"]},{"cell_type":"markdown","metadata":{"id":"QhkwmYinQO8p"},"source":["# Isolation Forest"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":820,"status":"ok","timestamp":1729320490483,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"HmlIOVx5QSLQ","outputId":"28e18c97-c1e9-4d80-852e-972d45a7f30e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Performance Metrics for Isolation Forest (using GroundTruth from IQR):\n","Accuracy: 0.90\n","Precision: 0.54\n","Recall: 0.28\n","F1-Score: 0.37\n","Evaluation metrics saved to hasil/BeforeRemoveOutliers/004_1_OutlierDetection_isolation_forest_evaluation.csv\n"]}],"source":["# Train and predict using Isolation Forest\n","iso_forest = IsolationForest(contamination=0.06, random_state=42)\n","iso_forest.fit(X_train)\n","y_pred_if = iso_forest.predict(X_test)\n","\n","# Performance Evaluation for Isolation Forest\n","\n","# Evaluate Isolation Forest using the IQR-based GroundTruth\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","precision_if = precision_score(y_test, y_pred_if, pos_label=-1)\n","recall_if = recall_score(y_test, y_pred_if, pos_label=-1)\n","f1_if = f1_score(y_test, y_pred_if, pos_label=-1)\n","\n","# Display performance metrics for Isolation Forest\n","print(\"Performance Metrics for Isolation Forest (using GroundTruth from IQR):\")\n","print(f\"Accuracy: {accuracy_if:.2f}\")\n","print(f\"Precision: {precision_if:.2f}\")\n","print(f\"Recall: {recall_if:.2f}\")\n","print(f\"F1-Score: {f1_if:.2f}\")\n","\n","# Create a DataFrame to store the evaluation metrics\n","evaluation_metrics = pd.DataFrame({\n","    'Model': ['Isolation Forest'],\n","    'Accuracy': [accuracy_if],\n","    'Precision': [precision_if],\n","    'Recall': [recall_if],\n","    'F1-Score': [f1_if]\n","})\n","\n","# Save the DataFrame to a CSV file\n","csv_filename = 'hasil/BeforeRemoveOutliers/004_1_OutlierDetection_isolation_forest_evaluation.csv'\n","evaluation_metrics.to_csv(csv_filename, index=False)\n","\n","print(f\"Evaluation metrics saved to {csv_filename}\")"]},{"cell_type":"markdown","metadata":{"id":"n7g1rPwYSzeB"},"source":["#DBScan"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1729320490483,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"c-MkIGyBS1cQ","outputId":"96f29168-bdf6-4631-880e-cb0417fd5f64"},"outputs":[{"name":"stdout","output_type":"stream","text":["DBSCAN           - Accuracy: 0.74, Precision: 0.24, Recall: 0.71, F1-Score: 0.36\n"]}],"source":["# Train and predict using DBSCAN\n","dbscan = DBSCAN(eps=0.5, min_samples=2)\n","y_pred_db = dbscan.fit_predict(X_test)\n","\n","# Convert DBSCAN predictions to binary (outliers = -1, inliers = 1)\n","y_pred_db_binary = np.where(y_pred_db == -1, -1, 1)\n","\n","# Evaluate DBSCAN (using binary labels)\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","precision_db = precision_score(y_test, y_pred_db_binary, pos_label=-1)\n","recall_db = recall_score(y_test, y_pred_db_binary, pos_label=-1)\n","f1_db = f1_score(y_test, y_pred_db_binary, pos_label=-1)\n","\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","\n","# Create a DataFrame to store the evaluation metrics\n","evaluation_metrics_dbscan = pd.DataFrame({\n","    'Model': ['DBSCAN'],\n","    'Accuracy': [accuracy_db],\n","    'Precision': [precision_db],\n","    'Recall': [recall_db],\n","    'F1-Score': [f1_db]\n","})\n","\n","# Save the DataFrame to a CSV file\n","csv_filename_dbscan = 'hasil/BeforeRemoveOutliers/004_2_OutlierDetection_dbscan_evaluation.csv'\n","evaluation_metrics_dbscan.to_csv(csv_filename_dbscan, index=False)"]},{"cell_type":"markdown","metadata":{"id":"Cw5zqKDQTGVf"},"source":["# One Class SVM"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1729320490483,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"nvyjXCmZTH9x","outputId":"dd57b06c-fead-4512-8f9f-afb5f0260519"},"outputs":[{"name":"stdout","output_type":"stream","text":["One-Class SVM    - Accuracy: 0.89, Precision: 0.41, Recall: 0.20, F1-Score: 0.27\n","Evaluation metrics for One-Class SVM saved to hasil/BeforeRemoveOutliers/004_3_OutlierDetection_one_class_svm_evaluation.csv\n"]}],"source":["# Train and predict using One-Class SVM\n","ocsvm = OneClassSVM(nu=0.05, kernel='rbf', gamma='auto')\n","y_pred_svm = ocsvm.fit_predict(X_test)\n","\n","# Evaluate One-Class SVM\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","precision_svm = precision_score(y_test, y_pred_svm, pos_label=-1)\n","recall_svm = recall_score(y_test, y_pred_svm, pos_label=-1)\n","f1_svm = f1_score(y_test, y_pred_svm, pos_label=-1)\n","\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","\n","# Create a DataFrame to store the evaluation metrics\n","evaluation_metrics_svm = pd.DataFrame({\n","    'Model': ['One-Class SVM'],\n","    'Accuracy': [accuracy_svm],\n","    'Precision': [precision_svm],\n","    'Recall': [recall_svm],\n","    'F1-Score': [f1_svm]\n","})\n","\n","# Save the DataFrame to a CSV file\n","csv_filename_svm = 'hasil/BeforeRemoveOutliers/004_3_OutlierDetection_one_class_svm_evaluation.csv'\n","evaluation_metrics_svm.to_csv(csv_filename_svm, index=False)\n","\n","print(f\"Evaluation metrics for One-Class SVM saved to {csv_filename_svm}\")"]},{"cell_type":"markdown","metadata":{"id":"7G9X-52NTYb4"},"source":["# Display Performance for each model"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1729320490483,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"6AHOGmA_TcDP","outputId":"9a26ed3f-2e68-4687-84b3-1bc851e486cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Performance Metrics for Individual Models:\n","Isolation Forest - Accuracy: 0.90, Precision: 0.54, Recall: 0.28, F1-Score: 0.37\n","DBSCAN           - Accuracy: 0.74, Precision: 0.24, Recall: 0.71, F1-Score: 0.36\n","One-Class SVM    - Accuracy: 0.89, Precision: 0.41, Recall: 0.20, F1-Score: 0.27\n"]}],"source":["# Display performance metrics for each model\n","print(\"Performance Metrics for Individual Models:\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation metrics for all models saved to hasil/BeforeRemoveOutliers/004_4_OutlierDetection_evaluation_metrics_all_models.csv\n"]}],"source":["# Create a DataFrame to store the evaluation metrics for all models\n","evaluation_metrics_all_models = pd.DataFrame({\n","    'Model': ['Isolation Forest', 'DBSCAN', 'One-Class SVM'],\n","    'Accuracy': [accuracy_if, accuracy_db, accuracy_svm],\n","    'Precision': [precision_if, precision_db, precision_svm],\n","    'Recall': [recall_if, recall_db, recall_svm],\n","    'F1-Score': [f1_if, f1_db, f1_svm]\n","})\n","\n","# Save the DataFrame to a CSV file\n","csv_filename_all_models = 'hasil/BeforeRemoveOutliers/004_4_OutlierDetection_evaluation_metrics_all_models.csv'\n","evaluation_metrics_all_models.to_csv(csv_filename_all_models, index=False)\n","\n","print(f\"Evaluation metrics for all models saved to {csv_filename_all_models}\")"]},{"cell_type":"markdown","metadata":{"id":"YglqO2sST6aQ"},"source":["# Ensemble (Manual)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1729320490875,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"HEHooUIjT8DB","outputId":"dfd2a16a-17c1-486a-c6d4-3f3f06787c91"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Performance Metrics for Majority Voting Ensemble:\n","Majority Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Performance Metrics for Weighted Voting Ensemble:\n","Weighted Voting - Accuracy: 0.91, Error Rate: 0.09, Precision: 0.61, Recall: 0.28, F1-Score: 0.38\n","\n","Performance Metrics for Individual Models, Majority Voting, and Weighted Voting:\n","Isolation Forest - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.54, Recall: 0.28, F1-Score: 0.37\n","DBSCAN           - Accuracy: 0.74, Error Rate: 0.26, Precision: 0.24, Recall: 0.71, F1-Score: 0.36\n","One-Class SVM    - Accuracy: 0.89, Error Rate: 0.11, Precision: 0.41, Recall: 0.20, F1-Score: 0.27\n","Majority Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","Weighted Voting  - Accuracy: 0.91, Error Rate: 0.09, Precision: 0.61, Recall: 0.28, F1-Score: 0.38\n"]}],"source":["# Combine the predictions using majority voting\n","import numpy as np\n","from scipy import stats\n","\n","# Collect predictions from all models\n","predictions = np.vstack([y_pred_if, y_pred_db_binary, y_pred_svm]).T\n","\n","# Majority voting (mode of predictions)\n","y_pred_ensemble_majority = stats.mode(predictions, axis=1)[0].flatten()\n","\n","# Evaluate the majority voting ensemble's performance\n","accuracy_majority = accuracy_score(y_test, y_pred_ensemble_majority)\n","error_rate_majority = 1 - accuracy_majority\n","precision_majority = precision_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","recall_majority = recall_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","f1_majority = f1_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Majority Voting Ensemble:\")\n","print(f\"Majority Voting - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","\n","# Weighted Voting\n","# Assign weights to the models (you can adjust these based on individual model performance)\n","weights = [0.5, 0.1, 0.4]  # Example: 40% for Isolation Forest, 30% for DBSCAN, 30% for One-Class SVM\n","\n","# Convert the predictions from (-1, 1) to (0, 1) for easier summing\n","predictions_binary = np.where(predictions == -1, 0, 1)\n","\n","# Perform weighted voting\n","weighted_sum = np.dot(predictions_binary, weights)\n","\n","# Setup threshold\n","threshold = 0.5\n","\n","# Convert weighted sum back to (-1, 1) labels: if sum >= 0.5, predict inlier (1); else outlier (-1)\n","y_pred_ensemble_weighted = np.where(weighted_sum >= threshold, 1, -1)\n","\n","# Evaluate the weighted voting ensemble's performance\n","accuracy_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n","error_rate_weighted = 1 - accuracy_weighted\n","precision_weighted = precision_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","recall_weighted = recall_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","f1_weighted = f1_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Weighted Voting Ensemble:\")\n","print(f\"Weighted Voting - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# Display performance comparison for all models and ensembles\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","error_rate_if = 1 - accuracy_if\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","error_rate_db = 1 - accuracy_db\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","error_rate_svm = 1 - accuracy_svm\n","\n","print(\"\\nPerformance Metrics for Individual Models, Majority Voting, and Weighted Voting:\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Error Rate: {error_rate_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Error Rate: {error_rate_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Error Rate: {error_rate_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","print(f\"Majority Voting  - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","print(f\"Weighted Voting  - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# # Check if the models are making diverse predictions\n","# agreement = np.sum(np.all(predictions == predictions[:, [0]], axis=1)) / len(predictions)\n","# print(f\"Percentage of total agreement between all models: {agreement * 100:.2f}%\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation metrics for all models and ensembles saved to hasil/BeforeRemoveOutliers/004_5_OutlierDetection_evaluation_metrics_models_and_ensembles.csv\n"]}],"source":["# Create a DataFrame to store the evaluation metrics for all models\n","evaluation_metrics = pd.DataFrame({\n","    'Model': ['Isolation Forest', 'DBSCAN', 'One-Class SVM', 'Majority Voting', 'Weighted Voting'],\n","    'Accuracy': [accuracy_if, accuracy_db, accuracy_svm, accuracy_majority, accuracy_weighted],\n","    'Error Rate': [error_rate_if, error_rate_db, error_rate_svm, error_rate_majority, error_rate_weighted],\n","    'Precision': [precision_if, precision_db, precision_svm, precision_majority, precision_weighted],\n","    'Recall': [recall_if, recall_db, recall_svm, recall_majority, recall_weighted],\n","    'F1-Score': [f1_if, f1_db, f1_svm, f1_majority, f1_weighted]\n","})\n","\n","# Save the DataFrame to a CSV file\n","csv_filename = 'hasil/BeforeRemoveOutliers/004_5_OutlierDetection_evaluation_metrics_models_and_ensembles.csv'\n","evaluation_metrics.to_csv(csv_filename, index=False)\n","\n","print(f\"Evaluation metrics for all models and ensembles saved to {csv_filename}\")"]},{"cell_type":"markdown","metadata":{"id":"AAdSjezzeXF4"},"source":["# Ensemble base on accuracy"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729320490876,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"M0EXn8fkeanQ","outputId":"5d44b704-6f33-47f9-b57e-96474ad8377c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Performance Metrics for Majority Voting Ensemble:\n","Majority Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Weights based on Accuracy: [0.35701702877275393, 0.29125073399882556, 0.3517322372284204]\n","\n","Performance Metrics for Weighted Voting Ensemble (using Accuracy as Weights):\n","Weighted Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Performance Metrics for Individual Models, Majority Voting, and Weighted Voting (using Accuracy as Weights):\n","Isolation Forest - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.54, Recall: 0.28, F1-Score: 0.37\n","DBSCAN           - Accuracy: 0.74, Error Rate: 0.26, Precision: 0.24, Recall: 0.71, F1-Score: 0.36\n","One-Class SVM    - Accuracy: 0.89, Error Rate: 0.11, Precision: 0.41, Recall: 0.20, F1-Score: 0.27\n","Majority Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","Weighted Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n"]}],"source":["import numpy as np\n","from scipy import stats\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Collect predictions from all models\n","predictions = np.vstack([y_pred_if, y_pred_db_binary, y_pred_svm]).T\n","\n","# Majority voting (mode of predictions)\n","y_pred_ensemble_majority = stats.mode(predictions, axis=1)[0].flatten()\n","\n","# Evaluate the majority voting ensemble's performance\n","accuracy_majority = accuracy_score(y_test, y_pred_ensemble_majority)\n","error_rate_majority = 1 - accuracy_majority\n","precision_majority = precision_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","recall_majority = recall_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","f1_majority = f1_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Majority Voting Ensemble:\")\n","print(f\"Majority Voting - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","\n","# Step 1: Calculate the accuracy for each model\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","\n","# Step 2: Normalize the accuracies to create weights\n","total_accuracy = accuracy_if + accuracy_db + accuracy_svm\n","weights = [accuracy_if / total_accuracy, accuracy_db / total_accuracy, accuracy_svm / total_accuracy]\n","\n","print(f\"\\nWeights based on Accuracy: {weights}\")\n","\n","# Convert the predictions from (-1, 1) to (0, 1) for easier summing\n","predictions_binary = np.where(predictions == -1, 0, 1)\n","\n","# Perform weighted voting\n","weighted_sum = np.dot(predictions_binary, weights)\n","\n","# Setup threshold\n","threshold = 0.5\n","\n","# Convert weighted sum back to (-1, 1) labels: if sum >= 0.5, predict inlier (1); else outlier (-1)\n","y_pred_ensemble_weighted = np.where(weighted_sum >= threshold, 1, -1)\n","\n","# Evaluate the weighted voting ensemble's performance\n","accuracy_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n","error_rate_weighted = 1 - accuracy_weighted\n","precision_weighted = precision_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","recall_weighted = recall_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","f1_weighted = f1_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Weighted Voting Ensemble (using Accuracy as Weights):\")\n","print(f\"Weighted Voting - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# Display performance comparison for all models and ensembles\n","error_rate_if = 1 - accuracy_if\n","error_rate_db = 1 - accuracy_db\n","error_rate_svm = 1 - accuracy_svm\n","\n","print(\"\\nPerformance Metrics for Individual Models, Majority Voting, and Weighted Voting (using Accuracy as Weights):\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Error Rate: {error_rate_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Error Rate: {error_rate_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Error Rate: {error_rate_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","print(f\"Majority Voting  - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","print(f\"Weighted Voting  - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"U9AUmZGvfBjY"},"source":["# Ensemble Base On Precision"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1729320490876,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"6y4cgzI7fOb3","outputId":"8230fdb9-6563-4c21-d31e-07f6b3ad3114"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Performance Metrics for Majority Voting Ensemble:\n","Majority Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Weights based on Precision: [0.45567058085885054, 0.1986969352079656, 0.34563248393318385]\n","\n","Performance Metrics for Weighted Voting Ensemble (using Precision as Weights):\n","Weighted Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Performance Metrics for Individual Models, Majority Voting, and Weighted Voting (using Precision as Weights):\n","Isolation Forest - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.54, Recall: 0.28, F1-Score: 0.37\n","DBSCAN           - Accuracy: 0.74, Error Rate: 0.26, Precision: 0.24, Recall: 0.71, F1-Score: 0.36\n","One-Class SVM    - Accuracy: 0.89, Error Rate: 0.11, Precision: 0.41, Recall: 0.20, F1-Score: 0.27\n","Majority Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","Weighted Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n"]}],"source":["import numpy as np\n","from scipy import stats\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Collect predictions from all models\n","predictions = np.vstack([y_pred_if, y_pred_db_binary, y_pred_svm]).T\n","\n","# Majority voting (mode of predictions)\n","y_pred_ensemble_majority = stats.mode(predictions, axis=1)[0].flatten()\n","\n","# Evaluate the majority voting ensemble's performance\n","accuracy_majority = accuracy_score(y_test, y_pred_ensemble_majority)\n","error_rate_majority = 1 - accuracy_majority\n","precision_majority = precision_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","recall_majority = recall_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","f1_majority = f1_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Majority Voting Ensemble:\")\n","print(f\"Majority Voting - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","\n","# Step 1: Calculate the precision for each model\n","precision_if = precision_score(y_test, y_pred_if, pos_label=-1)\n","precision_db = precision_score(y_test, y_pred_db_binary, pos_label=-1)\n","precision_svm = precision_score(y_test, y_pred_svm, pos_label=-1)\n","\n","# Step 2: Normalize the precisions to create weights\n","total_precision = precision_if + precision_db + precision_svm\n","weights = [precision_if / total_precision, precision_db / total_precision, precision_svm / total_precision]\n","\n","print(f\"\\nWeights based on Precision: {weights}\")\n","\n","# Convert the predictions from (-1, 1) to (0, 1) for easier summing\n","predictions_binary = np.where(predictions == -1, 0, 1)\n","\n","# Perform weighted voting\n","weighted_sum = np.dot(predictions_binary, weights)\n","\n","# Setup threshold\n","threshold = 0.5\n","\n","# Convert weighted sum back to (-1, 1) labels: if sum >= 0.5, predict inlier (1); else outlier (-1)\n","y_pred_ensemble_weighted = np.where(weighted_sum >= threshold, 1, -1)\n","\n","# Evaluate the weighted voting ensemble's performance\n","accuracy_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n","error_rate_weighted = 1 - accuracy_weighted\n","precision_weighted = precision_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","recall_weighted = recall_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","f1_weighted = f1_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Weighted Voting Ensemble (using Precision as Weights):\")\n","print(f\"Weighted Voting - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# Display performance comparison for all models and ensembles\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","error_rate_if = 1 - accuracy_if\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","error_rate_db = 1 - accuracy_db\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","error_rate_svm = 1 - accuracy_svm\n","\n","print(\"\\nPerformance Metrics for Individual Models, Majority Voting, and Weighted Voting (using Precision as Weights):\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Error Rate: {error_rate_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Error Rate: {error_rate_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Error Rate: {error_rate_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","print(f\"Majority Voting  - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","print(f\"Weighted Voting  - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QiOagqXtfuTP"},"source":["# Ensmble bas on F1 - Score"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1729320491245,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"8yFQ4i-Qfx7o","outputId":"2a3ff73d-f5ea-4e0e-ca77-3204621cb395"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Performance Metrics for Majority Voting Ensemble:\n","Majority Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Weights based on F1 Score: [0.3682192632506087, 0.357827110130645, 0.2739536266187462]\n","\n","Performance Metrics for Weighted Voting Ensemble (using F1 Score as Weights):\n","Weighted Voting - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","\n","Performance Metrics for Individual Models, Majority Voting, and Weighted Voting (using F1 Score as Weights):\n","Isolation Forest - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.54, Recall: 0.28, F1-Score: 0.37\n","DBSCAN           - Accuracy: 0.74, Error Rate: 0.26, Precision: 0.24, Recall: 0.71, F1-Score: 0.36\n","One-Class SVM    - Accuracy: 0.89, Error Rate: 0.11, Precision: 0.41, Recall: 0.20, F1-Score: 0.27\n","Majority Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n","Weighted Voting  - Accuracy: 0.90, Error Rate: 0.10, Precision: 0.50, Recall: 0.29, F1-Score: 0.37\n"]}],"source":["import numpy as np\n","from scipy import stats\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Collect predictions from all models\n","predictions = np.vstack([y_pred_if, y_pred_db_binary, y_pred_svm]).T\n","\n","# Majority voting (mode of predictions)\n","y_pred_ensemble_majority = stats.mode(predictions, axis=1)[0].flatten()\n","\n","# Evaluate the majority voting ensemble's performance\n","accuracy_majority = accuracy_score(y_test, y_pred_ensemble_majority)\n","error_rate_majority = 1 - accuracy_majority\n","precision_majority = precision_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","recall_majority = recall_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","f1_majority = f1_score(y_test, y_pred_ensemble_majority, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Majority Voting Ensemble:\")\n","print(f\"Majority Voting - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","\n","# Step 1: Calculate the F1 Score for each model\n","f1_if = f1_score(y_test, y_pred_if, pos_label=-1)\n","f1_db = f1_score(y_test, y_pred_db_binary, pos_label=-1)\n","f1_svm = f1_score(y_test, y_pred_svm, pos_label=-1)\n","\n","# Step 2: Normalize the F1 Scores to create weights\n","total_f1 = f1_if + f1_db + f1_svm\n","weights = [f1_if / total_f1, f1_db / total_f1, f1_svm / total_f1]\n","\n","print(f\"\\nWeights based on F1 Score: {weights}\")\n","\n","# Convert the predictions from (-1, 1) to (0, 1) for easier summing\n","predictions_binary = np.where(predictions == -1, 0, 1)\n","\n","# Perform weighted voting\n","weighted_sum = np.dot(predictions_binary, weights)\n","\n","# Setup threshold\n","threshold = 0.5\n","\n","# Convert weighted sum back to (-1, 1) labels: if sum >= 0.5, predict inlier (1); else outlier (-1)\n","y_pred_ensemble_weighted = np.where(weighted_sum >= threshold, 1, -1)\n","\n","# Evaluate the weighted voting ensemble's performance\n","accuracy_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n","error_rate_weighted = 1 - accuracy_weighted\n","precision_weighted = precision_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","recall_weighted = recall_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","f1_weighted = f1_score(y_test, y_pred_ensemble_weighted, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Weighted Voting Ensemble (using F1 Score as Weights):\")\n","print(f\"Weighted Voting - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","\n","# Display performance comparison for all models and ensembles\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","error_rate_if = 1 - accuracy_if\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","error_rate_db = 1 - accuracy_db\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","error_rate_svm = 1 - accuracy_svm\n","\n","print(\"\\nPerformance Metrics for Individual Models, Majority Voting, and Weighted Voting (using F1 Score as Weights):\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Error Rate: {error_rate_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Error Rate: {error_rate_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Error Rate: {error_rate_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","print(f\"Majority Voting  - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","print(f\"Weighted Voting  - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"udpWkvzEhVix"},"source":["# Stacking"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"elapsed":426,"status":"error","timestamp":1729320491670,"user":{"displayName":"Ahmad Muslikh","userId":"10473513443774370558"},"user_tz":-420},"id":"TNTFjMUghW5f","outputId":"a283e747-001a-419c-f172-12e3a980e49a"},"outputs":[{"ename":"NameError","evalue":"name 'y_train_binary' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[40], line 36\u001b[0m\n\u001b[0;32m     25\u001b[0m stacking_clf \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[0;32m     26\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     27\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso_forest\u001b[39m\u001b[38;5;124m'\u001b[39m, iso_forest),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     stack_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Fit stacking model\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m stacking_clf\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[43my_train_binary\u001b[49m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Predict using stacking ensemble\u001b[39;00m\n\u001b[0;32m     39\u001b[0m y_pred_stacking \u001b[38;5;241m=\u001b[39m stacking_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n","\u001b[1;31mNameError\u001b[0m: name 'y_train_binary' is not defined"]}],"source":["\n","# # Train Isolation Forest, DBSCAN, and One-Class SVM as base models\n","# iso_forest = IsolationForest(random_state=42)\n","# ocsvm = OneClassSVM(gamma='auto')\n","# dbscan = DBSCAN(eps=0.5, min_samples=5)  # Note: DBSCAN does not have a fit-predict method that returns probabilities\n","\n","# # Convert DBSCAN binary predictions (as it doesn't support probability)\n","# dbscan.fit(X_train)\n","# dbscan_pred_train = np.where(dbscan.fit_predict(X_train) == 1, 1, 0)\n","# dbscan_pred_test = np.where(dbscan.fit_predict(X_test) == 1, 1, 0)\n","\n","# Wrap DBSCAN predictions into a classifier-like function for stacking\n","# Pertama, lu harus import dulu StackingClassifier\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","class DBSCANWrapper(BaseEstimator, ClassifierMixin):\n","    def fit(self, X, y=None):\n","        self.model = DBSCAN(eps=0.5, min_samples=5)\n","        self.model.fit(X)\n","        return self\n","\n","    def predict(self, X):\n","        return np.where(self.model.fit_predict(X) == 1, 1, 0)\n","\n","# Stacking classifier with meta-learner as logistic regression\n","stacking_clf = StackingClassifier(\n","    estimators=[\n","        ('iso_forest', iso_forest),\n","        ('dbscan', DBSCANWrapper()),\n","        ('ocsvm', ocsvm)\n","    ],\n","    final_estimator=LogisticRegression(),\n","    stack_method='predict'\n",")\n","\n","# Fit stacking model\n","stacking_clf.fit(X_train, y_train_binary)\n","\n","# Predict using stacking ensemble\n","y_pred_stacking = stacking_clf.predict(X_test)\n","\n","# Convert stacking predictions back to (-1, 1)\n","y_pred_stacking = np.where(y_pred_stacking == 0, -1, 1)\n","\n","# Evaluate the stacking ensemble's performance\n","accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n","error_rate_stacking = 1 - accuracy_stacking\n","precision_stacking = precision_score(y_test, y_pred_stacking, pos_label=-1)\n","recall_stacking = recall_score(y_test, y_pred_stacking, pos_label=-1)\n","f1_stacking = f1_score(y_test, y_pred_stacking, pos_label=-1)\n","\n","print(\"\\nPerformance Metrics for Stacking Ensemble:\")\n","print(f\"Stacking - Accuracy: {accuracy_stacking:.2f}, Error Rate: {error_rate_stacking:.2f}, Precision: {precision_stacking:.2f}, Recall: {recall_stacking:.2f}, F1-Score: {f1_stacking:.2f}\")\n","\n","# Display performance comparison for all models and ensembles\n","accuracy_if = accuracy_score(y_test, y_pred_if)\n","error_rate_if = 1 - accuracy_if\n","accuracy_db = accuracy_score(y_test, y_pred_db_binary)\n","error_rate_db = 1 - accuracy_db\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","error_rate_svm = 1 - accuracy_svm\n","\n","print(\"\\nPerformance Metrics for Individual Models, Majority Voting, Weighted Voting, and Stacking:\")\n","print(f\"Isolation Forest - Accuracy: {accuracy_if:.2f}, Error Rate: {error_rate_if:.2f}, Precision: {precision_if:.2f}, Recall: {recall_if:.2f}, F1-Score: {f1_if:.2f}\")\n","print(f\"DBSCAN           - Accuracy: {accuracy_db:.2f}, Error Rate: {error_rate_db:.2f}, Precision: {precision_db:.2f}, Recall: {recall_db:.2f}, F1-Score: {f1_db:.2f}\")\n","print(f\"One-Class SVM    - Accuracy: {accuracy_svm:.2f}, Error Rate: {error_rate_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n","print(f\"Majority Voting  - Accuracy: {accuracy_majority:.2f}, Error Rate: {error_rate_majority:.2f}, Precision: {precision_majority:.2f}, Recall: {recall_majority:.2f}, F1-Score: {f1_majority:.2f}\")\n","print(f\"Weighted Voting  - Accuracy: {accuracy_weighted:.2f}, Error Rate: {error_rate_weighted:.2f}, Precision: {precision_weighted:.2f}, Recall: {recall_weighted:.2f}, F1-Score: {f1_weighted:.2f}\")\n","print(f\"Stacking         - Accuracy: {accuracy_stacking:.2f}, Error Rate: {error_rate_stacking:.2f}, Precision: {precision_stacking:.2f}, Recall: {recall_stacking:.2f}, F1-Score: {f1_stacking:.2f}\")\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[{"file_id":"1vJhvTpTD3PhtaGxMW_n5Cetro-tiwIQ0","timestamp":1729313878490},{"file_id":"1vbBEsonBcBXmX52xLaImBBbGy0cpusr-","timestamp":1728013139100},{"file_id":"1M_85TxDI7JhjFXkmHyUeKBkpTccvcnt0","timestamp":1727407593051},{"file_id":"1tCNl-JcueGmNpD4OxRNyLuleUUXsMYH_","timestamp":1726220211340},{"file_id":"1bElswYxfkl4uI372RGL86wuwHZywTgJL","timestamp":1726140131893}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
