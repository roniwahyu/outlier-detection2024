{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.cblof import CBLOF\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "file_path = \"dataset/agriculture_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to handle missing values\n",
    "def handle_missing_values(data, column, strategy='mean'):\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    data[[column]] = imputer.fit_transform(data[[column]])\n",
    "    return data\n",
    "\n",
    "# Define the function for IQR outlier detection\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    data[f'iqr_outlier'] = np.where((data[column] < lower_bound) | (data[column] > upper_bound), -1, 1)\n",
    "    return data\n",
    "\n",
    "# Define the function for Z-Score outlier detection\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    data['zscore'] = (data[column] - data[column].mean()) / data[column].std()\n",
    "    data[f'zscore_outlier'] = np.where(np.abs(data['zscore']) > threshold, -1, 1)\n",
    "    data.drop(columns=['zscore'], inplace=True)\n",
    "    return data\n",
    "\n",
    "# Define the function for combined IQR and Z-Score outlier detection\n",
    "# def detect_outliers_iqr_zscore(data, column):\n",
    "#     data = detect_outliers_iqr(data, column)\n",
    "#     data = detect_outliers_zscore(data, column)\n",
    "#     data['iqr_zscore_outlier'] = np.where((data['iqr_outlier'] == -1) & (data['zscore_outlier'] == -1), -1, 1)\n",
    "#     return data\n",
    "\n",
    "# Define the function for Isolation Forest outlier detection\n",
    "def detect_outliers_isolation_forest(data, column):\n",
    "    iso_forest = IsolationForest(contamination=0.05)\n",
    "    labels = iso_forest.fit_predict(data[[column]])\n",
    "    data[f'if_outlier'] = np.where(labels == -1, -1, 1)\n",
    "    return data\n",
    "\n",
    "# Define the function for DBSCAN outlier detection\n",
    "def detect_outliers_dbscan(data, column):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[[column]])\n",
    "    dbscan = DBSCAN(eps=0.3, min_samples=10)\n",
    "    labels = dbscan.fit_predict(scaled_data)\n",
    "    data[f'dbscan_outlier'] = np.where(labels == -1, -1, 1)\n",
    "    return data\n",
    "\n",
    "# Define the function for One-Class SVM outlier detection\n",
    "def detect_outliers_one_class_svm(data, column):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[[column]])\n",
    "    svm = OneClassSVM(nu=0.05)\n",
    "    labels = svm.fit_predict(scaled_data)\n",
    "    data[f'ocsvm_outlier'] = np.where(labels == -1, -1, 1)\n",
    "    return data\n",
    "\n",
    "# Define the function for Local Outlier Factor (LOF) outlier detection\n",
    "def detect_outliers_lof(data, column):\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "    labels = lof.fit_predict(data[[column]])\n",
    "    data[f'lof_outlier'] = np.where(labels == -1, -1, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Define the function for Gaussian Naive Bayes outlier detection using the Gaussian PDF\n",
    "def detect_outliers_gaussian(data, column, threshold=0.01):\n",
    "    # Calculate the mean and standard deviation of the column\n",
    "    mean = data[column].mean()\n",
    "    std_dev = data[column].std()\n",
    "    \n",
    "    # Calculate the probability density for each point\n",
    "    pdf_values = norm.pdf(data[column], mean, std_dev)\n",
    "    \n",
    "    # Label outliers as -1 if their probability density is below the threshold\n",
    "    data[f'gaussian_outlier'] = np.where(pdf_values < threshold, -1, 1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# HBOS (Histogram-based Outlier Score)\n",
    "def detect_outliers_hbos(data, column):\n",
    "    hbos = HBOS()\n",
    "    hbos.fit(data[[column]])\n",
    "    scores = hbos.decision_function(data[[column]])\n",
    "    threshold = np.percentile(scores, 95)\n",
    "    data[f'hbos_outlier'] = np.where(scores > threshold, -1, 1)\n",
    "    return data\n",
    "\n",
    "# CBLOF (Cluster-Based Local Outlier Factor)\n",
    "def detect_outliers_cblof(data, column):\n",
    "    cblof = CBLOF()\n",
    "    cblof.fit(data[[column]])\n",
    "    labels = cblof.predict(data[[column]])\n",
    "    data[f'cblof_outlier'] = np.where(labels == 1, 1, -1)  # CBLOF marks outliers as 1\n",
    "    return data\n",
    "\n",
    "# # Mahalanobis Distance\n",
    "# def detect_outliers_mahalanobis(data, column):\n",
    "#     mean = np.mean(data[column])\n",
    "#     cov = np.cov(data[column].T)\n",
    "#     inv_covmat = np.linalg.inv(cov)\n",
    "#     data['mahalanobis'] = data.apply(lambda row: Mahalanobis(row[column], mean, inv_covmat), axis=1)\n",
    "#     threshold = np.percentile(data['mahalanobis'], 95)\n",
    "#     data[f'mahalanobis_outlier'] = np.where(data['mahalanobis'] > threshold, -1, 1)\n",
    "#     data.drop(columns=['mahalanobis'], inplace=True)\n",
    "#     return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# Function to compute Mahalanobis distance\n",
    "def Mahalanobis(x, mean, inv_covmat):\n",
    "    x_minus_mu = x - mean\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return np.sqrt(mahal)\n",
    "\n",
    "# Function to detect outliers using Mahalanobis Distance\n",
    "def detect_outliers_mahalanobis(data, column):\n",
    "    # Ensure the column is in 2D\n",
    "    values = data[[column]].values\n",
    "    \n",
    "    # Calculate mean and covariance matrix\n",
    "    mean = np.mean(values, axis=0)\n",
    "    cov = np.cov(values, rowvar=False)\n",
    "    inv_covmat = np.linalg.inv(cov)\n",
    "\n",
    "    # Compute Mahalanobis distance for each row\n",
    "    data['mahalanobis'] = data.apply(lambda row: Mahalanobis(np.array([row[column]]), mean, inv_covmat), axis=1)\n",
    "\n",
    "    # Determine threshold for outliers (95th percentile)\n",
    "    threshold = np.percentile(data['mahalanobis'], 95)\n",
    "    data['mahalanobis_outlier'] = np.where(data['mahalanobis'] > threshold, -1, 1)\n",
    "    \n",
    "    # Drop the intermediate Mahalanobis distance column\n",
    "    data.drop(columns=['mahalanobis'], inplace=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return pd.DataFrame(scaled_data, columns=data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle missing values\n",
    "def handle_missing_values(data, column, strategy='mean'):\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    data[[column]] = imputer.fit_transform(data[[column]])\n",
    "    return data\n",
    "\n",
    "# Function to detect outliers using a combination of Isolation Forest and Local Outlier Factor\n",
    "def detect_outliers_if_lof(data, column):\n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.05)\n",
    "    if_labels = iso_forest.fit_predict(data[[column]])\n",
    "    \n",
    "    # Local Outlier Factor\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "    lof_labels = lof.fit_predict(data[[column]])\n",
    "    \n",
    "    # Combining results\n",
    "    combined_labels = np.where((if_labels == -1) & (lof_labels == -1), -1, 1)\n",
    "    data[f'if_lof_outlier'] = combined_labels\n",
    "    return data\n",
    "\n",
    "# Function to detect outliers using a combination of Isolation Forest, Gaussian PDF, and Local Outlier Factor\n",
    "def detect_outliers_if_gaussian_lof(data, column):\n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.05)\n",
    "    if_labels = iso_forest.fit_predict(data[[column]])\n",
    "    \n",
    "    # Gaussian PDF\n",
    "    mean = data[column].mean()\n",
    "    std = data[column].std()\n",
    "    gaussian_pdf = norm.pdf(data[column], mean, std)\n",
    "    threshold = 0.01  # Assuming a threshold for the PDF\n",
    "    gaussian_labels = np.where(gaussian_pdf < threshold, -1, 1)\n",
    "    \n",
    "    # Local Outlier Factor\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "    lof_labels = lof.fit_predict(data[[column]])\n",
    "    \n",
    "    # Combining results\n",
    "    combined_labels = np.where((if_labels == -1) & (gaussian_labels == -1) & (lof_labels == -1), -1, 1)\n",
    "    data[f'if_gaussian_lof_outlier'] = combined_labels\n",
    "    return data\n",
    "\n",
    "# Function to detect outliers using a combination of Isolation Forest, DBSCAN, and One-Class SVM\n",
    "def detect_outliers_if_dbscan_svm(data, column):\n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.05)\n",
    "    if_labels = iso_forest.fit_predict(data[[column]])\n",
    "    \n",
    "    # DBSCAN\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[[column]].values.reshape(-1, 1))\n",
    "    dbscan = DBSCAN(eps=0.3, min_samples=10)\n",
    "    dbscan_labels = dbscan.fit_predict(scaled_data)\n",
    "    dbscan_labels = np.where(dbscan_labels == -1, -1, 1)  # Convert DBSCAN labels to -1 and 1\n",
    "    \n",
    "    # One-Class SVM\n",
    "    svm = OneClassSVM(nu=0.05)\n",
    "    svm_labels = svm.fit_predict(scaled_data)\n",
    "    \n",
    "    # Combining results\n",
    "    combined_labels = np.where((if_labels == -1) & (dbscan_labels == -1) & (svm_labels == -1), -1, 1)\n",
    "    data[f'if_dbscan_svm_outlier'] = combined_labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using Gaussian Naive Bayes (GNB)\n",
    "def detect_outliers_gnb(data, column, threshold=0.01):\n",
    "    # Fit Gaussian Naive Bayes model\n",
    "    gnb = GaussianNB()\n",
    "    data_reshaped = data[[column]].values.reshape(-1, 1)\n",
    "    \n",
    "    # GNB requires labels for fitting; we'll use a dummy label array\n",
    "    dummy_labels = np.zeros(data_reshaped.shape[0])\n",
    "    \n",
    "    # Fit the model (ignoring the labels)\n",
    "    gnb.fit(data_reshaped, dummy_labels)\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    probabilities = gnb.predict_proba(data_reshaped)[:, 0]  # probability of the only class\n",
    "    \n",
    "    # Detect outliers based on the threshold\n",
    "    outliers = probabilities < threshold\n",
    "    data[f'gnb_outlier'] = np.where(outliers, -1, 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify outliers using Gaussian Naive Bayes\n",
    "def classify_outliers(data, column='N2O'):\n",
    "    gnb = GaussianNB()\n",
    "    X = data.drop(columns=[column])\n",
    "    y = data[column]\n",
    "    \n",
    "    # Train the model\n",
    "    gnb.fit(X, y)\n",
    "    \n",
    "    # Predict the outliers\n",
    "    y_pred = gnb.predict(X)\n",
    "    \n",
    "    # Classify as -1 for outlier, 1 for inlier based on the model prediction\n",
    "    outlier_labels = np.where(y_pred == y.min(), -1, 1)  # Adjust the threshold as needed\n",
    "    \n",
    "    # Add the outlier labels to the original data\n",
    "    data['Outlier'] = outlier_labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_gaussian_nb(data, target_column):\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    # First, use Isolation Forest to create an initial set of outlier labels\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    iso_outliers = iso_forest.fit_predict(X)\n",
    "    \n",
    "    # Map the Isolation Forest labels to binary labels: 1 for inliers, -1 for outliers\n",
    "    binary_outliers = np.where(iso_outliers == 1, 1, -1)\n",
    "    \n",
    "    # Train GaussianNB using the binary outlier labels\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X, binary_outliers)\n",
    "    \n",
    "    # Predict outliers (-1 for outliers, 1 for inliers) using GaussianNB\n",
    "    outlier_labels = nb_model.predict(X)\n",
    "    \n",
    "    # Add outlier labels to the original dataframe\n",
    "    data['gaussian_nb_outlier'] = outlier_labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "# Define the function for Gaussian PDF outlier detection\n",
    "def detect_outliers_gaussian_pdf(data, column, threshold=0.01):\n",
    "    mean = data[column].mean()\n",
    "    std = data[column].std()\n",
    "    pdf_values = norm.pdf(data[column], mean, std)\n",
    "    data[f'gaussianpdf_outlier'] = np.where(pdf_values < threshold, -1, 1)\n",
    "    return data\n",
    "\n",
    "# Define the function for Bayesian Gaussian Mixture Model (BGM) outlier detection\n",
    "def detect_outliers_bayesian_gmm(data, column, n_components=2):\n",
    "    bgm = BayesianGaussianMixture(n_components=n_components, covariance_type='full', random_state=42)\n",
    "    bgm.fit(data[[column]])\n",
    "    log_probs = bgm.score_samples(data[[column]])\n",
    "    data[f'bgm_outlier'] = np.where(log_probs < np.percentile(log_probs, 5), -1, 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the missing value handler\n",
    "\n",
    "data = handle_missing_values(df, 'N2O', strategy='mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply each outlier detection method\n",
    "data = detect_outliers_iqr(data, 'N2O')\n",
    "data = detect_outliers_zscore(data, 'N2O')\n",
    "# data = detect_outliers_iqr_zscore(data, 'N2O')\n",
    "data = detect_outliers_isolation_forest(data, 'N2O')\n",
    "data = detect_outliers_dbscan(data, 'N2O')\n",
    "data = detect_outliers_one_class_svm(data, 'N2O')\n",
    "data = detect_outliers_lof(data, 'N2O')\n",
    "data = detect_outliers_gaussian(data, 'N2O')\n",
    "# data = detect_outliers_hbos(data, 'N2O')\n",
    "# data = detect_outliers_cblof(data, 'N2O')\n",
    "# data = detect_outliers_mahalanobis(data, 'N2O')\n",
    "# data = detect_outliers_kmeans(data, 'N2O')\n",
    "# data = detect_outliers_knn(data, 'N2O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply combined outlier detection methods\n",
    "data = detect_outliers_if_lof(data, 'N2O')\n",
    "data = detect_outliers_if_gaussian_lof(data, 'N2O')\n",
    "data = detect_outliers_if_dbscan_svm(data, 'N2O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = detect_outliers_gnb(data, 'N2O')\n",
    "# data = detect_outliers_gaussian_nb(data, 'N2O')\n",
    "data = detect_outliers_gaussian_pdf(data, 'N2O')\n",
    "data = detect_outliers_bayesian_gmm(data, 'N2O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to integrate Isolation Forest and LOF for outlier detection\n",
    "def integrate_if_lof(data, column):\n",
    "    # Normalize the feature\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(data[[column]])\n",
    "    \n",
    "    # Fit Isolation Forest and get outlier scores\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    iso_forest.fit(X_scaled)\n",
    "    if_probabilities = -iso_forest.decision_function(X_scaled)  # Higher scores for outliers\n",
    "\n",
    "    # Fit LOF and get outlier scores\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "    lof_scores = -lof.fit_predict(X_scaled)  # Higher scores for outliers\n",
    "    lof_scores = lof.negative_outlier_factor_\n",
    "\n",
    "    # Integrate scores\n",
    "    integrated_scores = (if_probabilities + lof_scores) / 2\n",
    "\n",
    "    return X_scaled, integrated_scores\n",
    "\n",
    "# Function to classify outliers using Naive Bayes\n",
    "def classify_outliers_naive_bayes(data, column, threshold_percentile=90):\n",
    "    # Handle missing values\n",
    "    data = handle_missing_values(data, column, strategy='mean')\n",
    "    \n",
    "    # Integrate IF and LOF scores\n",
    "    X_scaled, integrated_scores = integrate_if_lof(data, column)\n",
    "    \n",
    "    # Determine threshold for outliers\n",
    "    threshold = np.percentile(integrated_scores, threshold_percentile)\n",
    "    \n",
    "    # Binary labels for Naive Bayes (1 for inliers, -1 for outliers)\n",
    "    labels = np.where(integrated_scores > threshold, -1, 1)\n",
    "    \n",
    "    # Split data for training and testing\n",
    "    X_train, X_test, labels_train, labels_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train GaussianNB model for outlier classification\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, labels_train)\n",
    "    \n",
    "    # Predict outliers on the full dataset\n",
    "    data['nb_outlier'] = nb_model.predict(X_scaled)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = classify_outliers_naive_bayes(data, 'N2O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the updated data with outlier column\n",
    "# data = detect_outliers_hbos(data, 'N2O')\n",
    "# data = detect_outliers_cblof(data, 'N2O')\n",
    "# data = detect_outliers_mahalanobis(data, 'N2O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('hasil/0905_2_N2O_Agriculture_OutlierDetection_5_Update09062024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the count of outliers and inliers for each method\n",
    "\n",
    "def summarize_outliers(df, method_columns):\n",
    "    summary = []\n",
    "    for column in method_columns:\n",
    "        inliers = df[column].value_counts().get(1, 0)\n",
    "        outliers = df[column].value_counts().get(-1, 0) if df[column].min() == -1 else df[column].value_counts().get(0, 0)\n",
    "        total = len(df[column])\n",
    "        summary.append({\n",
    "            'Method': column.replace('_outlier', ''),\n",
    "            'Outliers': outliers,\n",
    "            'Inliers': inliers,\n",
    "            'Total': total\n",
    "        })\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# List of outlier detection columns\n",
    "outlier_columns = [col for col in df.columns if col.endswith('_outlier')]\n",
    "\n",
    "# Generate the summary\n",
    "summary_df = summarize_outliers(df, outlier_columns)\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Outlier Detection Summary\", dataframe=summary_df)\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to summarize the count of inliers and outliers for each method\n",
    "def summarize_outliers(data, methods):\n",
    "    summary = []\n",
    "    for method in methods:\n",
    "        inliers = (data[f'{method}_outlier'] == 1).sum()\n",
    "        outliers = (data[f'{method}_outlier'] == -1).sum()\n",
    "        total = inliers + outliers\n",
    "        summary.append({'Method': method, 'Inliers': inliers, 'Outliers': outliers, 'Total': total})\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "# List of methods used for outlier detection\n",
    "methods = ['iqr', 'zscore','if', 'dbscan', 'ocsvm', 'lof','gaussian']\n",
    "\n",
    "# Generate the summary\n",
    "summary_df = summarize_outliers(data, methods)\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Outlier Detection Summary\", dataframe=summary_df)\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the figure layout\n",
    "fig, axes = plt.subplots(6, 2, figsize=(15, 18))\n",
    "\n",
    "# List of methods for outlier detection\n",
    "# methods = ['IQR', 'ZScore', 'IQR_ZScore', 'IF', 'DBSCAN', 'OneClassSVM', 'LOF', 'NaiveBayes']\n",
    "# methods = ['IQR', 'ZScore','IQR_ZScore', 'IF', 'DBSCAN', 'OneClassSVM', 'LOF','NaiveBayes','IF_LOF','IF_Gaussian_LOF','IF_DBSCAN_SVM']\n",
    "methods = ['iqr', 'zscore','iqr_zscore', 'if', 'dbscan', 'ocsvm', 'lof','nb','if_lof','if_gaussian_lof','if_dbscan_svm']\n",
    "\n",
    "# Define a function to plot outliers for each method\n",
    "def plot_outliers(data, method, ax):\n",
    "    sns.scatterplot(x=data.index, y=data['N2O'], hue=data[f'{method}_outlier'], palette={1: 'blue', -1: 'red'}, ax=ax)\n",
    "    ax.set_title(f'{method} Outlier Detection')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('N2O Levels')\n",
    "    ax.legend(title='Outlier', loc='upper right')\n",
    "\n",
    "# Create a plot for each method\n",
    "for i, method in enumerate(methods[:12]):\n",
    "    plot_outliers(data, method, axes[i // 2, i % 2])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the plotting code to handle the correct number of subplots (3 rows x 2 columns for 6 methods)\n",
    "# Removing one of the methods from the plotting to fit the layout or handle separately\n",
    "\n",
    "# List of methods used for outlier detection (reduced to 6 for fitting 3x2 layout)\n",
    "# methods = ['IQR', 'ZScore', 'IQR_ZScore', 'IF', 'DBSCAN', 'OneClassSVM', 'LOF','NaiveBayes']\n",
    "# List of methods used for outlier detection (reduced to 6 for fitting 3x2 layout)\n",
    "methods_to_plot = ['IQR', 'ZScore', 'IQR_ZScore', 'IF', 'DBSCAN', 'OneClassSVM','LOF','NaiveBayes']\n",
    "\n",
    "# Create subplots with 3 rows and 2 columns\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 15))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each method\n",
    "for i, method in enumerate(methods_to_plot):\n",
    "    ax = axes[i]\n",
    "    inliers = data[data[f'{method}_outlier'] == 1]['N2O']\n",
    "    outliers = data[data[f'{method}_outlier'] == -1]['N2O']\n",
    "    \n",
    "    ax.hist(inliers, bins=30, alpha=0.5, label='Inliers', color='green')\n",
    "    ax.hist(outliers, bins=30, alpha=0.5, label='Outliers', color='red')\n",
    "    ax.set_title(f'{method} Outlier Detection')\n",
    "    ax.set_xlabel('N2O')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust layout to prevent overlapping titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure proper indexing, we'll adjust the loop to match the correct number of subplots and handle exceptions.\n",
    "\n",
    "def plot_outlier_comparison_final(summary_df):\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(14, 18))\n",
    "    fig.suptitle('Outlier Detection Methods Comparison', fontsize=16)\n",
    "    axes = axes.flatten()\n",
    "    methods = summary_df['Method']\n",
    "\n",
    "    # Plot each method\n",
    "    for i, method in enumerate(methods):\n",
    "        if i < len(axes):  # Ensure we don't access out-of-bound indexes\n",
    "            axes[i].bar(['Inliers', 'Outliers'], summary_df.loc[i, ['Inliers', 'Outliers']], color=['skyblue', 'salmon'])\n",
    "            axes[i].set_title(f'{method} Method')\n",
    "            axes[i].set_xlabel('Category')\n",
    "            axes[i].set_ylabel('Count')\n",
    "            axes[i].set_ylim(0, summary_df['Total'].max() + 100)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(len(methods), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the comparison with the final corrected version\n",
    "plot_outlier_comparison_final(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the layout for the subplots\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 18))\n",
    "fig.suptitle('Outlier Detection Methods Comparison', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Method list and their corresponding titles for the plots\n",
    "methods = ['IQR', 'ZScore', 'IQR_ZScore', 'IF', 'DBSCAN', 'OneClassSVM', 'LOF','NaiveBayes']\n",
    "titles = ['IQR', 'Z-Score', 'IQR + Z-Score', 'Isolation Forest', 'DBSCAN', 'One-Class SVM', 'Local Outlier Factor','Gaussian PDF']\n",
    "\n",
    "# Generate boxplots for each method\n",
    "for i, method in enumerate(methods):\n",
    "    if i < len(axes):\n",
    "        sns.boxplot(\n",
    "            x=data[f'{method}_outlier'].astype(str),  # Convert labels to strings for the palette\n",
    "            y=data['N2O'], \n",
    "            ax=axes[i], \n",
    "            palette={'1': 'lightblue', '-1': 'red'}\n",
    "        )\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].set_xlabel('Outlier Label')\n",
    "        axes[i].set_ylabel('N2O Levels')\n",
    "        axes[i].set_xticks([0, 1])\n",
    "        axes[i].set_xticklabels(['Outlier', 'Inlier'])\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the layout for 4 rows and 2 columns to accommodate all methods\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 20))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# List of methods and corresponding names for visualization\n",
    "methods_for_viz = ['IQR', 'ZScore', 'IQR_ZScore', 'IF', 'DBSCAN', 'OneClassSVM', 'LOF','NaiveBayes']\n",
    "method_names = ['IQR', 'Z-Score', 'IQR & Z-Score', 'Isolation Forest', 'DBSCAN', 'One-Class SVM', 'LOF','Gaussian PDF']\n",
    "\n",
    "# Plot each method's outliers\n",
    "for i, method in enumerate(methods_for_viz):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    sns.boxplot(x='N2O', y=f'{method}_outlier', data=data, ax=axes[row, col], orient='h')\n",
    "    axes[row, col].set_title(f'{method_names[i]} Outlier Detection')\n",
    "    axes[row, col].set_yticks([-1, 1])\n",
    "    axes[row, col].set_yticklabels(['Outlier (-1)', 'Inlier (1)'])\n",
    "    for tick in axes[row, col].get_yticklabels():\n",
    "        tick.set_rotation(0)\n",
    "\n",
    "# Hide the unused subplot if the number of methods is odd\n",
    "if len(methods_for_viz) % 2 != 0:\n",
    "    fig.delaxes(axes[3, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
