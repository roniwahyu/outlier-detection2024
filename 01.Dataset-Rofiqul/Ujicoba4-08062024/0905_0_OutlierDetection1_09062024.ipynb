{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'dataset/agriculture_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows of the dataset to understand its structure\n",
    "# print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Date    Year Experiment   DataUse Replication     Month Vegetation  \\\n",
      "0   2/9/12  2012.0   BCSE_KBS  Building          R1  February       Corn   \n",
      "1  2/10/12  2012.0   BCSE_KBS  Building          R1  February       Corn   \n",
      "2  2/18/12  2012.0   BCSE_KBS  Building          R1  February       Corn   \n",
      "3  2/19/12  2012.0   BCSE_KBS  Building          R1  February       Corn   \n",
      "4  3/16/12  2012.0   BCSE_KBS  Building          R1     March       Corn   \n",
      "\n",
      "  VegType       N2O  N_rate  ...   PP7  AirT  DAF_TD  DAF_SD  WFPS25cm  \\\n",
      "0  Annual  3.896742   170.0  ...  0.00  -2.0   276.0   241.0  0.666508   \n",
      "1  Annual  2.190218   170.0  ...  0.00  -2.4   277.0   242.0  0.640608   \n",
      "2  Annual  3.542594   170.0  ...  8.64   0.3   285.0   250.0  0.728085   \n",
      "3  Annual  3.342870   170.0  ...  8.13  -3.8   286.0   251.0  0.686872   \n",
      "4  Annual  2.947778   170.0  ...  8.39  17.6   312.0   277.0  0.716221   \n",
      "\n",
      "         NH4        NO3  Clay   Sand       SOM  \n",
      "0  11.046340  22.940812  62.5  637.5  1.174072  \n",
      "1  11.008087  22.959578  62.5  637.5  1.174072  \n",
      "2  10.831669  23.221928  62.5  637.5  1.174072  \n",
      "3  10.849792  23.271978  62.5  637.5  1.174072  \n",
      "4  10.204748  24.206855  62.5  637.5  1.174072  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Identify numeric and non-numeric columns\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns.tolist()\n",
    "non_numeric_columns = data.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "# Column containing N2O measurements (replace 'N2O' with the actual column name)\n",
    "n2o_column = 'N2O'  # Update this to the correct column name if necessary\n",
    "\n",
    "# Handle missing values\n",
    "# Impute numeric columns with mean or median\n",
    "numeric_imputer = SimpleImputer(strategy='mean')  # Change to 'median' if preferred\n",
    "data[numeric_columns] = numeric_imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Impute non-numeric columns with the most frequent value\n",
    "if non_numeric_columns:\n",
    "    non_numeric_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data[non_numeric_columns] = non_numeric_imputer.fit_transform(data[non_numeric_columns])\n",
    "\n",
    "# Define outlier detection methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iqr_zscore filtered data to hasil/iqr_zscore_filtered.csv\n",
      "Saved isolation_forest filtered data to hasil/isolation_forest_filtered.csv\n",
      "Saved dbscan filtered data to hasil/dbscan_filtered.csv\n",
      "Saved oneclass_svm filtered data to hasil/oneclass_svm_filtered.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([ -7.4152966 ,  -5.22679564,  -5.09184177, ..., 324.265     ,\n       583.149     , 593.072     ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name, method_func \u001b[38;5;129;01min\u001b[39;00m methods\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnaive_bayes\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         df_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutlier_detection_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn2o_column\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         df_filtered \u001b[38;5;241m=\u001b[39m method_func(data, outlier_detection_columns)\n",
      "Cell \u001b[1;32mIn[65], line 39\u001b[0m, in \u001b[0;36mnaive_bayes_outliers\u001b[1;34m(df, columns, target)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnaive_bayes_outliers\u001b[39m(df, columns, target):\n\u001b[0;32m     38\u001b[0m     nb \u001b[38;5;241m=\u001b[39m GaussianNB()\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     outlier_prob \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mpredict_proba(df[columns])[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     41\u001b[0m     df_filtered \u001b[38;5;241m=\u001b[39m df[outlier_prob \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m]  \u001b[38;5;66;03m# Threshold for outliers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:422\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _refit:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[43m_check_partial_fit_first_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:440\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` is not the same as on last call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto partial_fit, was: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (classes, clf\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    436\u001b[0m             )\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;66;03m# This is the first call to partial_fit\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m         clf\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# nothing to do\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:106\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    104\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([ -7.4152966 ,  -5.22679564,  -5.09184177, ..., 324.265     ,\n       583.149     , 593.072     ]),)"
     ]
    }
   ],
   "source": [
    "# IQR & ZScore\n",
    "def iqr_zscore_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "# Isolation Forest\n",
    "def isolation_forest_outliers(df, columns):\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    outliers = iso_forest.fit_predict(df[columns])\n",
    "    df_filtered = df[outliers == 1]\n",
    "    return df_filtered\n",
    "\n",
    "# DBSCAN\n",
    "def dbscan_outliers(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df[columns])\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    outliers = dbscan.fit_predict(df_scaled)\n",
    "    df_filtered = df[outliers != -1]\n",
    "    return df_filtered\n",
    "\n",
    "# OneClass SVM\n",
    "def oneclass_svm_outliers(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df[columns])\n",
    "    oc_svm = OneClassSVM(nu=0.1)\n",
    "    outliers = oc_svm.fit_predict(df_scaled)\n",
    "    df_filtered = df[outliers == 1]\n",
    "    return df_filtered\n",
    "\n",
    "# Naive Bayes\n",
    "def naive_bayes_outliers(df, columns, target):\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(df[columns], df[target])\n",
    "    outlier_prob = nb.predict_proba(df[columns])[:, 1]\n",
    "    df_filtered = df[outlier_prob >= 0.1]  # Threshold for outliers\n",
    "    return df_filtered\n",
    "\n",
    "# Local Outlier Factor (LOF)\n",
    "def lof_outliers(df, columns):\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "    outliers = lof.fit_predict(df[columns])\n",
    "    df_filtered = df[outliers == 1]\n",
    "    return df_filtered\n",
    "\n",
    "# List of columns used for outlier detection (excluding the target)\n",
    "outlier_detection_columns = numeric_columns.copy()\n",
    "outlier_detection_columns.remove(n2o_column)\n",
    "\n",
    "# Apply each outlier detection method and save the result\n",
    "methods = {\n",
    "    'iqr_zscore': iqr_zscore_outliers,\n",
    "    'isolation_forest': isolation_forest_outliers,\n",
    "    'dbscan': dbscan_outliers,\n",
    "    'oneclass_svm': oneclass_svm_outliers,\n",
    "    'naive_bayes': naive_bayes_outliers,\n",
    "    'lof': lof_outliers\n",
    "}\n",
    "\n",
    "for method_name, method_func in methods.items():\n",
    "    if method_name == 'naive_bayes':\n",
    "        df_filtered = method_func(data, outlier_detection_columns, n2o_column)\n",
    "    else:\n",
    "        df_filtered = method_func(data, outlier_detection_columns)\n",
    "    \n",
    "    # Save the filtered dataframe to a CSV file\n",
    "    output_path = f'hasil/{method_name}_filtered.csv'\n",
    "    df_filtered.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {method_name} filtered data to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
